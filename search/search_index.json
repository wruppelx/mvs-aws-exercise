{"config":{"lang":["de"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Versuchsanleitung","text":""},{"location":"#kurzfassung","title":"Kurzfassung","text":"<p>In dieser praktischen \u00dcbung zum Thema Cloud-Transcodierung soll ein grundlegendes Verst\u00e4ndnis f\u00fcr cloudbasierte Transcodierung f\u00fcr Video-on-Demand-Systeme geschaffen werden. Au\u00dferdem sollen erste Praxiserfahrungen mit den Cloud-Anbietern AWS und Akamai vermittelt werden.</p>"},{"location":"#versuche-im-uberblick","title":"Versuche im \u00dcberblick","text":"Nr. Beschreibung Versuch 1 Grundlegende Konzepte eines Cloud-Transcoders Versuch 2 Grundlegende Konzepte eines CDNs Versuch 3 Aufbau eines automatisierten VOD-Workflows Versuch 4 Kommandozeilenbefehle und APIs"},{"location":"#abgabe","title":"Abgabe","text":"<p>Bewertet wird ein schriftlicher Versuchsbericht sowie die im Laufe der Versuchsdurchf\u00fchrung erzeugten Dateien. Der schriftliche Bericht sollte grob 3 Seiten pro Versuch umfassen und neben der Protokollierung der Versuchsdurchf\u00fchrung die in der Versuchsanleitung gestellten Fragen beantworten. </p> <p>Die Fragen sind in der Versuchsanleitung folgenderma\u00dfen gekennzeichnet:</p> <p>Beispielfrage 1</p> <p>Beispiel-Fragestellung.</p>"},{"location":"#abgabeort","title":"Abgabeort","text":"<p>Die Abgabe des Versuchsberichtes erfolgt via ILIAS. Der Versuchsbericht soll nach dem folgenden Schema benannt sein: </p> <p><code>[Matrikelnummer] - [Nachname]_[Vorname] - Versuchsbericht.pdf</code></p> <p>Die abzugebenden Dateien sollen in Ihr S3-Bucket hochgeladen werden. Pro Versuch soll f\u00fcr die Abgaben ein eigener Ordner erstellt werden. </p> <p>Im Fazit jedes Kapitels sind die Dateien genannt, die mindestens abgegeben werden m\u00fcssen. Eigene Experimente mit z.B. kreativen Kodiereinstellungen etc. sind erw\u00fcnscht. Wenn weitere Dateien auf S3 verbleiben, kopieren Sie diese bitte in einen Unterordner \"Experimente\".</p> <p>Beispiel:</p> <pre><code>\ud83d\udcc1 \n    \ud83d\udcc1 Versuch 1\n        \ud83d\udcc4 Clip1_720p.mp4\n        ...\n    \ud83d\udcc1 Versuch 2\n    \ud83d\udcc1 Versuch 3\n    \ud83d\udcc1 Versuch 4\n    \ud83d\udcc1 Versuch 5\n</code></pre> <p>Warnung</p> <p>Dateien, die sich nicht im Abgabeordner befinden, werden bei der Bewertung nicht ber\u00fccksichtigt.</p>"},{"location":"#bewertungskriterien","title":"Bewertungskriterien","text":"<p>Zur Bewertung werden sowohl der Versuchsbericht, als auch die beantworteten Fragen sowie die abgegebenen Dateien herangezogen. Neben faktischer Korrektheit sollte ebenfalls auf die Rechtschreibung und Form (z.B. Quellenangaben) geachtet werden.</p>"},{"location":"#benotigte-software","title":"Ben\u00f6tigte Software","text":"<p>F\u00fcr die Versuche ist nur wenig Software auf dem lokalen Rechner von N\u00f6ten, da auf AWS und Akamai \u00fcber ein Webinterface zugegriffen wird. Zur Beurteilung der Dateien sind jedoch einige Programme notwendig. </p> <p>Alle Programme sind sowohl f\u00fcr Windows und MacOS, als auch f\u00fcr diverse Linux-Distributionen erh\u00e4ltlich.</p>"},{"location":"#mediaplayer","title":"Mediaplayer","text":"<p>Zur Wiedergabe von transcodierten Videodateien sollte ein aktueller Mediaplayer vorhanden sein. Empfohlen wird VLC Mediaplayer oder mpv.</p>"},{"location":"#mediainfo","title":"MediaInfo","text":"<p>Um die technischen Metadaten der Videodateien auszulesen, wird MediaInfo ben\u00f6tigt.</p> <p></p>"},{"location":"einleitung/","title":"Einleitung","text":"<p>Video-on-Demand-Systeme (VoD) sind aus dem allt\u00e4glichen Leben nicht wegzudenken - Youtube, Netflix und die ARD/ZDF-Mediathek. Der Aufbau eines VoD-Systems in der Cloud ist in den letzten Jahren denkbar einfach geworden. Cloud-Anbieter wie Amazon Web Services (AWS) und Akamai bieten verschiedene Werkzeuge an, um Medien zu ingestieren, zu speichern, zu konvertieren und letztendlich zu verbreiten.</p>"},{"location":"einleitung/#workflow","title":"Workflow","text":"<p>Grunds\u00e4tzlich folgt der Distributionsweg bei VoD-Systemen meist einem \u00e4hnlichen Ablauf: Die Quelldateien werden in hoher Qualit\u00e4t in das System eingespeist und nicht \u00f6ffentlich gespeichert. Je nach Distributionsweg kann die Quelldatei in verschiedene Distributionsformate transcodiert werden, um auf verschiedenen Ger\u00e4ten wiedergegeben werden zu k\u00f6nnen. Die transcodierten Dateien k\u00f6nnen au\u00dferdem mit einem Kopierschutz versehen werden.</p> <p>Sind die verschiedenen Distributionspakete erstellt, k\u00f6nnen sie \u00fcber ein Content-Delivery-Network (CDN) verteilt werden. Nutzer greifen dabei \u00fcber eine Weboberfl\u00e4che (Frontend) auf die im CDN gespeicherten Medien (Backend) zu.</p> <p> </p> <p>In der Praxis wird dieser simple Ablauf noch mit verschiedenen Steuerungs- und Monitoriung-Werkzeugen erg\u00e4nzt, um Arbeitsschritte zu automatisieren oder beispielsweise dem zust\u00e4ndigen Mitarbeiter Benachrichtigungen zu senden, sobald eine Datei transcodiert wurde.</p>"},{"location":"einleitung/#cloud-anbieter","title":"Cloud-Anbieter","text":"<p>\"The Cloud Is Just Someone Else's Computer\"</p> <p>Cloud-Anbieter sind Firmen, die Rechenleistung oder \u00e4hnliche Dienstleistungen f\u00fcr ihre Kunden anbieten. Der Nutzer muss keine eigene Hardware bereitstellen, sondern mietet diese f\u00fcr einen gewissen Zeitraum an. Bei Bedarf k\u00f6nnen so flexibel und f\u00fcr einen kurzen Zeitraum mehr oder weniger Ressourcen gebucht werden.</p> <p>Das Angebot kann man grob in 3 Bereiche unterteilen: </p> <ul> <li> <p>Infrastructure as a Service (IaaS) stellt Computing- oder Netzwerk-Infrastruktur wie Server und Router zur Verf\u00fcgung. </p> </li> <li> <p>Platform as a Service (PaaS) bietet Plattformen wie Speicherplatz oder Kubernetes-Cluster an, ohne dass sich der Kunde mit dem darunterliegenden Betriebssystem befassen muss. </p> </li> <li> <p>Software as a Service (SaaS) abstrahiert weiter und stellt reine Softwarel\u00f6sungen wie Transcoder oder Benachrichtigungen zur Verf\u00fcgung<sup>1</sup>. </p> </li> </ul> <p>Einige Cloud-Anbieter sind AWS, Microsoft Azure, Akamai oder Linode.</p> <p>Info</p> <p>F\u00fcr die folgenden Versuche werden die Plattformen von AWS f\u00fcr Speicherung, Monitoring und Transcodierung sowie das Content-Delivery-Network von Akamai benutzt.</p> <p>Kosten</p> <p>Produkte von Cloud-Anbietern werden meist pro Zeiteinheit abgerechnet. Wenn beispielsweise ein erstellter Server nach Benutzung nicht wieder abgeschaltet/gel\u00f6scht wird, k\u00f6nnen hohe Kosten entstehen, die erst bei der monatlichen Abrechnung offensichtlich werden. Wenn f\u00fcr ein automatisiertes Skripten 100 statt 10 Instanzen startet, k\u00f6nnen die Kosten ebenfalls schnell in die H\u00f6he schie\u00dfen.</p>"},{"location":"einleitung/#weboberflache","title":"Weboberfl\u00e4che","text":"<p>Cloud-Produkte lassen sich am einfachsten \u00fcber eine grafische Weboberfl\u00e4che einrichten und bedienen. Diese bietet die \u00fcbersichtliche Bedienung, ist jedoch weniger leicht zu automatisieren. Mithilfe der Log-in-Daten k\u00f6nnen mit wenigen Klicks Ressourcen hinzugef\u00fcgt oder entfernt werden. Die Weboberfl\u00e4che nennt sich bei AWS \"Konsole\".</p>"},{"location":"einleitung/#kommandozeile","title":"Kommandozeile","text":"<p>Neben der grafischen Oberfl\u00e4che k\u00f6nnen Cloud-Ressourcen auch mithilfe von Kommandozeilen-Anwendungen (CLI) sowie Skripten bestellt und bedient werden. Zwar ist dies nicht so \u00fcbersichtlich f\u00fcr Anf\u00e4nger, jedoch k\u00f6nnen fortgeschrittene Nutzer schneller und automatisierter Ressourcen buchen und Workflows erstellen.</p> <ol> <li> <p>Der Begriff dient au\u00dferdem zur Beschreibung von Gesch\u00e4ftsmodellen, die Software per Abonnement zur Verf\u00fcgung stellen. Diese Software muss nicht zwingend in der Cloud betrieben werden, hat aber oft Verkn\u00fcpfungen zu beispielsweise Cloud-Speicher Diensten (z.B. Adobe Creative Cloud).\u00a0\u21a9</p> </li> </ol>"},{"location":"versuch1/01-einfuehrung/","title":"Einf\u00fchrung","text":"<p>Zuerst werden f\u00fcr diesen Versuch die Grundbegriffe gekl\u00e4rt und das Konzept erl\u00e4utert. Danach wird mithilfe der Schritt f\u00fcr Schritt Anleitung ein erster Transcodierauftrag erstellt und gestartet. Ziel ist es, nach Versuch 1 ein grundlegendes Verst\u00e4ndnis f\u00fcr Cloud-Transcoder zu haben und einen Cloud-Transcoder erstellen zu k\u00f6nnen.</p>"},{"location":"versuch1/01-einfuehrung/#grundbegriffe","title":"Grundbegriffe","text":""},{"location":"versuch1/01-einfuehrung/#cloud-speicher-aws-s3","title":"Cloud-Speicher (AWS S3)","text":"<p> Cloud-Speicher-L\u00f6sungen bieten \u00e4hnlich wie die Konsumerprodukte Dropbox, Google Drive etc. Speicherplatz an. Im Industriellen Umfeld wird oft Objektspeicher verwendet, welcher Informationen als Objekte ablegt und nicht wie Dateisysteme in hierarchische Ordnerstrukturen. Jedes Objekt besitz einen global einzigartigen Identifikator und wird in einem Bucket (deutsch: Eimer) gespeichert. </p> <p>Als Objektspeicher wird f\u00fcr diesen Versuch AWS S3 verwendet. Einzelne Objekte k\u00f6nnen bis zu 5 Terabyte gro\u00df sein und entweder \u00fcber die Web GUI oder \u00fcber verschiedene APIs hochgeladen werden. Hier werden sowohl die Quelldateien f\u00fcr den Versuch als auch die transcodierten Dateien gespeichert.</p> <p>Kosten</p> <p>Gespeicherte Dateien verursachen sowohl pro Zeiteinheit Speicherkosten als auch pro \u00fcbertragene Gigabyte Downloadkosten. Bei kleinen Datenmengen wie in diesen Versuchen belaufen sich die Kosten auf unter 1$ USD. Bei gro\u00dfen Projekten und Datenmengen k\u00f6nnen die Speicherkosten jedoch deutlich gr\u00f6\u00dfer sein.</p>"},{"location":"versuch1/01-einfuehrung/#transcodierer-aws-elemental-mediaconvert","title":"Transcodierer (AWS Elemental MediaConvert)","text":"<p> Als Software-as-a-Service L\u00f6sung bieten Cloud-Transcoder f\u00fcr verschiedenste Einsatzzwecke Transcodierungsleistungen, ohne dass sich die Nutzer um Hardware oder Betriebssysteme k\u00fcmmern m\u00fcssen.</p> <p>In diesem Versuch wird AWS Elemental MediaConvert verwendet. Nachdem ein Transcodierungsprofil erstellt worden ist, kann die Quelldatei aus dem S3 Objektspeicher gew\u00e4hlt werden und der Codierungsauftrag wird in die Warteschlange eingereiht. Ist die Transcodierung abgeschlossen, wird die transcodierte Datei im Objektspeicher abgelegt.</p> <p>Kosten</p> <p>Die Kosten pro Transcodierung h\u00e4ngen von Aufl\u00f6sung, Bildrate und Dauer der Quelldatei ab. Pro eine Minute Quellmaterial werden bei HD-Aufl\u00f6sung bspw. ca. 2 Cent USD f\u00e4llig. So fallen f\u00fcr die Transcodierung eines zweist\u00fcndigen Filmes ca 2,40$ USD an.</p>"},{"location":"versuch1/01-einfuehrung/#aws-webgui","title":"AWS WebGUI","text":""},{"location":"versuch1/01-einfuehrung/#log-in","title":"Log-in","text":"<p>In diesem Versuch greifen wir auf AWS \u00fcber die WebGUI zu. Einloggen kann man sich \u00fcber den Browser auf aws.amazon.com. In der Anmeldemaske kann man zwischen einem Stammbenutzer und einem IAM-Benutzer w\u00e4hlen. Die Hochschule stellt verwaltete IAM-Benutzer zur Verf\u00fcgung, daher muss diese Option gew\u00e4hlt werden. Die Kontonummer lautet <code>757773874047</code>, soweit nicht anders angegeben.</p> <p></p> <p>Nach Eingabe der bereitgestellten Kontonummer k\u00f6nnen auch der Benutzername sowie das Passwort eingegeben und der Log-in best\u00e4tigt werden. Das Passwort besteht aus dem Nutzernamen in Kleinbuchstaben, der Matrikelnummer und einem Ausrufezeichen. F\u00fcr den Nutzer <code>musterst</code> mit der Matrikelnummer <code>12345</code> w\u00fcrde das Passwort also <code>musterst12345!</code> lauten.</p> <p></p> <p>Bei der ersten Anmeldung muss das Passwort auf ein Nutzereigenes Passwort ge\u00e4ndert werden.</p> <p></p> <p>Das Dashboard ist der Startpunkt der AWS-Konsole und bietet die M\u00f6glichkeit, verschiedene Widgets anzuzeigen. Oben links lassen sich verschiedene Produkte und Services ausw\u00e4hlen. Diese k\u00f6nnen ebenso \u00fcber die Suchleiste gefunden werden. </p> <p></p>"},{"location":"versuch1/01-einfuehrung/#region","title":"Region","text":"<p>Oben rechts kann die Region, also der Standort des verwendeten Rechenzentrums, ver\u00e4ndert werden. F\u00fcr die Versuche ist die N\u00e4chstgelegende Region in diesem Fall Frankfurt (<code>eu-central-1</code>), die sinnvollste.</p> <p>Frage 1</p> <p>Eine Region beschreibt kein einzelnes Rechenzentrum. Recherchieren und erl\u00e4utern Sie die Begriffe \"Region\" und \"Availability Zone\". Wie sind Regionen und Availability Zones miteinander verbunden?</p> <p></p>"},{"location":"versuch1/02-S3/","title":"AWS S3","text":"<p>Zuerst muss der Speicherort f\u00fcr die transcodierten Dateien erstellt werden. Daf\u00fcr wird der S3 Objektspeicher verwendet. Auf der AWS Konsole l\u00e4sst sich S3 oben links unter <code>Services -&gt; Speicherung -&gt; S3</code> ausw\u00e4hlen oder \u00fcber die Suchleiste finden.</p> <p>Frage 2</p> <p>Welche Redundanzen und welche Zuverl\u00e4ssigkeit bietet S3-Objektspeicher laut Amazon? Was ist der Unterschied zwischen der Verf\u00fcgbarkeit des S3-Services und der Verf\u00fcgbarkeit eines einzelnen Objektes \u00fcber ein Jahr?</p> <p>\u00dcber die Seitenleiste l\u00e4sst sich die Option <code>Buckets</code> ausw\u00e4hlen. Hier werden die von diesem Konto erstellten Buckets, also Speicherorte, angezeigt. Dies schlie\u00dft auch jene ein, die von einem anderen IAM-Benutzer mit der gleichen Konto-ID erstellt wurden. Daher werden auch die Buckets der anderen Studierenden gelistet, obwohl die Benutzer der Studierenden nur Zugriff auf den eigenen Bucket haben.</p> <p></p>"},{"location":"versuch1/02-S3/#bucket-erstellen","title":"Bucket erstellen","text":"<p>Mithilfe des Buttons \"Bucket erstellen\" kann ein neuer Bucket erstellt werden. Der Bucket soll nach dem Schema <code>mvs-[HDS-Nutzername]</code> benannt werden, also beispielsweise <code>mvs-musterstudent</code>. Als AWS-Region soll Frankfurt (<code>eu-central-1</code>) gew\u00e4hlt werden. Alle anderen Einstellungen k\u00f6nnen auf ihren Standardeinstellungen belassen werden. Mit dem Button \"Bucket erstellen\" wird der angegeben Bucket erstellt.</p> <p>Info</p> <p>Der Name des Buckets muss weltweit eindeutig gew\u00e4hlt sein und darf keine Leerzeichen, Gro\u00dfbuchstaben oder Unterstriche enthalten.</p> <p></p> <p>Der neu erstellte Bucket solle nun in der Auflistung aller Buckets angezeigt werden.</p>"},{"location":"versuch1/02-S3/#unterordner-erstellen","title":"Unterordner erstellen","text":"<p>Info</p> <p>Das Prinzip der Objektspeicher sieht keine klassischen Ordner, wie sie in einem hierarchischen Dateisystem zu finden sind, vor. Um trotzdem Struktur in einen Bucket zu bringen, kann \u00fcber Pr\u00e4fixe der Form <code>foldername/file.extension</code> eine hierarchische Dateistruktur simuliert werden. In der AWS-Konsole werden diese Pr\u00e4fixe getrennt mit einem <code>/</code> wie ein hierarchisches Dateisystem angezeigt. Der Einfachheit halber werden diese Pr\u00e4fixe im Folgenden als Ordner bezeichnet.</p> <p>F\u00fcr die transcodierten Dateien soll ein Unterordner im Bucket erstellt werden. Dazu muss der Bucket durch das Klicken auf den Bucketnamen in der \u00dcbersicht aller Buckets ge\u00f6ffnet werden. Hier kann nun \u00fcber die Schaltfl\u00e4che \"Ordner erstellen\" ein Ordner im Bucket erstellt werden.</p> <p></p> <p>Als Name soll <code>Versuch1</code> gew\u00e4hlt werden. Ist der Ordner erstellt, wird dieser in der \u00dcbersicht des Buckets angezeigt.</p> <p></p>"},{"location":"versuch1/02-S3/#quelldateien","title":"Quelldateien","text":"<p>Die Quelldateien, die f\u00fcr den Transcodier-Auftrag verwendet werden sollen, wurden bereits auf S3 hochgeladen und liegen im Bucket <code>a--sourcefiles/IMFs</code>. Sie liegen im MXF Format und in einer hohen Bitrate vor, wie es auch bei professionellen Produktionen der Fall ist.</p> <p></p>"},{"location":"versuch1/03-transcoder/","title":"AWS MediaConvert","text":"<p>Um das Sample-Video zu transcodieren, wird AWS Elemental MediaConvert verwendet. Dieser Service ist unter <code>Services -&gt; Media Services -&gt; MediaConvert</code> zu finden. Mit dem Klick auf \"Erste Schritte\" kann ein Transcoder-Auftrag erstellt werden. </p> <p>Vorher sollte jedoch sicher gestellt werden, dass man sich in der Region Frankfurt (eu-central-1) befindet.</p> <p></p>"},{"location":"versuch1/03-transcoder/#warteschlange","title":"Warteschlange","text":"<p>Da auch bei MediaConvert die Auftr\u00e4ge von anderen IAM-Benutzern angezeigt werden, lohnt sich der \u00dcbersicht halber die Einordnung in Warteschlangen. Der Bereich \"Warteschlangen\" l\u00e4sst sich \u00fcber die Seitenleiste aufrufen.</p> <p></p> <p>Hier wurden bereits die maximale Anzahl von 10 Warteschlangen erstellt. Welche Warteschlange genutzt werden soll, wurde in der Mail mit den Zugangsdaten mitgeteilt.</p>"},{"location":"versuch1/03-transcoder/#transcodierauftrag-erstellen","title":"Transcodierauftrag erstellen","text":"<p>Um eine Videodatei in ein anderes Format zu transcodieren, muss ein Transcodierauftrag (Transcoding Job)  erstellt werden. Hier werden unter anderem die Transcodierparameter sowie der Ein- und Ausgabepfad festgelegt.</p> <p>Achtung!</p> <p>Der orangene Button \"Erstellen\" am unteren Ende der Seite erstellt und startet den Transcoding Job. Ist der Transcoding Job erstellt, k\u00f6nnen dessen Einstellungen nicht mehr ge\u00e4ndert werden und es muss ein neuer Job mit den ver\u00e4nderten Einstellungen erstellt werden.</p> <p>Klicken Sie daher erst auf \"Erstellen\", wenn alle Transcodiereinstellungen (das sind die folgenden Abschnitte Eingabe, Ausgabe, Berechtigungen und Rollen, Warteschlange) festgelegt sind!</p>"},{"location":"versuch1/03-transcoder/#eingabe","title":"Eingabe","text":"<p>Zuerst muss die Quelldatei bestimmt werden. Im Feld der Eingabedatei-URL kann manuell eine \u00f6ffentliche S3-, HTTP- oder HTTPS-URL angegeben werden oder durch die Schaltfl\u00e4che Durchsuchen eine Datei in den eigenen S3-Buckets ausgew\u00e4hlt werden. </p> <p></p> <p>Da die Quelldateien bereits im Bucket <code>a--sourcefiles</code> abgelegt wurden, kann dieser durch den Button \"Durchsuchen\" ausgew\u00e4hlt werden. Sobald man das Suchfeld \"Datei\" ausw\u00e4hlt, werden die verf\u00fcgbaren Dateien angezeigt. Hier muss die Composition Playlist (CPL) ausgew\u00e4hlt werden, damit MediaConvert die Quelldaten als MXF einlesen kann. F\u00fcr diesen ersten Versuch soll die CPL-Datei aus dem Ordner <code>IMFs/BBB-MVS-20221202/</code> gew\u00e4hlt werden.</p> <p></p> <p>Falls die Quelldatei vom Transcoder anders als in den Metadaten vermerkt interpretiert werden soll, kann diese Auswahl ebenfalls im Bereich Eingaben getroffen werden. F\u00fcr diesen Versuch m\u00fcssen diese Einstellungen jedoch nicht ver\u00e4ndert werden.</p>"},{"location":"versuch1/03-transcoder/#ausgabe","title":"Ausgabe","text":"<p>Im Bereich Ausgabegruppen kann ein oder mehrere Ausgabeformate festgelegt werden. F\u00fcr diesen Versuch soll die Option Dateigruppe gew\u00e4hlt werden, da einzelne Ausgabedateien erzeugt werden sollen.</p> <p>Im Reiter File Group l\u00e4sst sich nun unter anderem eine Zieladresse ausw\u00e4hlen. Hier w\u00e4hlen wir den im letzten Kapitel angelegten S3-Ordner <code>Versuch1</code> im eigenen S3-Bucket.</p> <p>F\u00fcr diesen Versuch soll die Quelldatei in folgende Formate transcodiert werden:</p> Aufl\u00f6sung Video Bitrate Audio Bitrate Namensmodifikator 1920x1080 5 Mbit/s 192 Kbit/s <code>_1080p</code> 1280x720 2,5 Mbit/s 128 Kbit/s <code>_720p</code> 848x480 1 Mbit/s 96 Kbit/s <code>_480p</code> <p>Daf\u00fcr k\u00f6nnen \u00fcber den Button \"Ausgabe hinzuf\u00fcgen\" mehrere Ausgaben erstellt werden und Namensmodifikatoren vergeben werden. Diese Modifikatoren werden an den Dateinamen der transcodierten Dateien angeh\u00e4ngt.</p> <p></p>"},{"location":"versuch1/03-transcoder/#videoformat","title":"Videoformat","text":"<p>Durch das Klicken auf den Namen der jeweiligen Ausgabe (z.B. \"Output 1\") werden die Codierungseinstellungen der jeweiligen Ausgabe ge\u00f6ffnet. Hier kann nun die gew\u00fcnschte Aufl\u00f6sung sowie der gew\u00fcnschte Modus der Bitrate und die dazugeh\u00f6rigen Parameter eingestellt werden. F\u00fcr alle Ausgaben soll eine feste Bitrate (CBR) verwendet werden.</p> <p>Die Parameter Aufl\u00f6sung und Bitrate k\u00f6nnen aus der vorangegangenen Tabelle entnommen werden. Die Qualit\u00e4tsoptimierungsebene soll auf \"HQ mit einem Durchgang\" gestellt werden.</p> <p>Warning</p> <p>Die Bitrate wird bei AWS in Bit/s und nicht in Mbit/s angegeben. Eine Umrechnung ist notwendig.</p> <p></p>"},{"location":"versuch1/03-transcoder/#timecode","title":"Timecode","text":"<p>Bei den erstellten Dateien soll der Timecode als Wasserzeichen in das Video \"eingebrannt\", also fest in das Video codiert werden. Daf\u00fcr muss in den Videocodier-Einstellungen ganz unten der Bereich \"Vorverarbeitung\" ausgeklappt und die Option \"Timecode einbrennen\" aktiviert werden. Die Bemerkung \"Pro\" neben der Option signalisiert, dass sich durch das Aktivieren der Option die Transcodiergeb\u00fchren erh\u00f6hen.</p> <p>Als Pr\u00e4fix soll der eigene HDS-Nutzername mit einem Bindestrich gew\u00e4hlt (also <code>musterstudent -</code>) werden, sodass <code>musterstudent - 00:00:00:00</code> im oberen Bereich des Bildes zu sehen ist. Als Schriftgr\u00f6\u00dfe soll \"Small\" gew\u00e4hlt werden. Die Position soll nicht ver\u00e4ndert werden. </p> <p></p>"},{"location":"versuch1/03-transcoder/#audioformat","title":"Audioformat","text":"<p>Durch die Auswahl \"Audio 1\" statt \"Video\" kann auch die Audiocodierung ver\u00e4ndert werden. Standardm\u00e4\u00dfig wird \"Fortgeschrittene Audiocodierung\" (Advanced Audio Coding / AAC) verwendet, es k\u00f6nnen jedoch auch verschiedene Dolby-Codecs ausgew\u00e4hlt werden.</p> <p>Hier muss nur die Audiobitrate anhand der Tabelle eingestellt werden. Soll ein anderes Format als Stereo verwendet werden, kann dies ebenfalls hier konfiguriert werden.</p> <p></p>"},{"location":"versuch1/03-transcoder/#berechtigungen-und-rolle","title":"Berechtigungen und Rolle","text":"<p>Berechtigungen und Rollen in AWS sind ein komplexeres Thema, das vor allem in Versuch 3 wichtig wird. F\u00fcr diesen Versuch ist nur wichtig, dass die richtige Rolle f\u00fcr den Transcodierauftrag gew\u00e4hlt wird. Dazu w\u00e4hlt man im linken Men\u00fc den Punkt \"AWS-Integration\" und kontrolliert, ob die \"MediaConvert_Default_Role\" ausgew\u00e4hlt ist.</p> <p></p>"},{"location":"versuch1/03-transcoder/#warteschlange_1","title":"Warteschlange","text":"<p>Als letzter Schritt muss im Men\u00fcpunkt \"Aufgabenverwaltung\" noch die eigene Warteschlange ausgew\u00e4hlt werden. Danach kann \u00fcber den Button \"Erstellen\" der Transcodierauftrag erstellt und gestartet werden. Welche Warteschlange genutzt werden soll, steht in der Mail mit den Zugangsdaten, die jeder Studierende bekommen haben sollte.</p> <p></p>"},{"location":"versuch1/03-transcoder/#uberwachung-des-transcodierauftrages","title":"\u00dcberwachung des Transcodierauftrages","text":"<p>Ist der Auftrag erstellt, erfolgt eine Weiterleitung auf die \"Aufgaben\u00fcbersicht\" des erstellten Auftrags, in der der aktuelle Stand des Auftrags angezeigt wird. Ist der Auftrag eingegangen, wird <code>SUBMITTED</code> im Status angezeigt. Die Aufgaben\u00fcbersicht wird nicht automatisch aktualisiert und muss daher manuell \u00fcber den Button \"Aktualisieren\" auf den aktuellen Stand gebracht werden.</p> <p>Frage 3</p> <p>Wie lange dauerte der Transcodiervorgang?</p> <p></p> <p>Wird der Auftrag bearbeitet, lautet der Status <code>PROGRESSING</code>.</p> <p></p> <p>Ist der Auftrag erledigt, wird der Status <code>COMPLETE</code> angezeigt.</p> <p></p> <p>Der Job kann auch in der \u00dcbersicht der Aufgaben angezeigt werden. Hier kann nach der Warteschlange gefiltert werden, um eine \u00fcbersichtliche Darstellung zu generieren.</p> <p></p>"},{"location":"versuch1/04-download/","title":"Download","text":"<p>Ist die Quelldatei fertig transcodiert, werden die resultierenden Dateien im eigenen Bucket angezeigt und k\u00f6nnen \u00fcber die S3-Weboberfl\u00e4che heruntergeladen werden.</p>"},{"location":"versuch1/04-download/#inspektion","title":"Inspektion","text":"<p>Zur Kontrolle, ob alle Codierungsparameter ber\u00fccksichtigt wurden, l\u00e4sst sich die Datei in MediaInfo \u00f6ffnen. MediaInfo zeigt detailliert Eigenschaften und Metadaten f\u00fcr vielerlei verschiedene Medien an. </p> <p>Schon die \u00dcbersicht zeigt die Videodatenrate und die Audiodatenrate. Ebenso werden die verwendeten Audio- und Video-Codecs angezeigt. In anderen Ansichten wie die \"Tree\"-Ansicht sind auch tiefer gehende Eigenschaften wie Farbraum und Chroma-Subsampling aufgelistet.</p> <p>Frage 4</p> <p>Welche Codierungsparameter wurden von MediaConvert f\u00fcr die verschiedenen Formate gew\u00e4hlt? Geben Sie die Parameter in einer Tabelle mit der folgenden Form an:</p> Parameter <code>_1080p</code> <code>_720p</code> <code>_480p</code> Container-Format Gesamtbitrate Video-Codec Codec-Profil / Level Video-Bitrate Aufl\u00f6sung (b x h) Chroma-Subsampling Farbtiefe Prim\u00e4rvalenzen Audio-Codec Audio-Bitrate <p></p>"},{"location":"versuch1/05-fazit/","title":"Fazit","text":"<p>In Versuch 1 wurden die Grundprinzipien eines Cloud-Transcoders erl\u00e4utert und ein erster Transcoder-Auftrag in AWS erstellt. Hierbei wurde eine Quelldatei mit hoher Bitrate in verschiedene Distributionsformate f\u00fcr verschiedene Bandbreiten und Endger\u00e4te konvertiert.</p> <p>Nach diesem Versuch sollten folgende Arbeitsabl\u00e4ufe klar sein:</p> <ul> <li>Erstellung eines AWS S3 Objektspeichers</li> <li>Erstellung eines Transcodier-Auftrags in AWS Elemental MediaConvert</li> <li>Download einer Datei von AWS S3</li> <li>\u00dcberpr\u00fcfen einer Datei auf dessen Audio- und Video-Parameter</li> </ul>"},{"location":"versuch1/05-fazit/#abgabe","title":"Abgabe","text":"<p>In der Abgabe sollten die 3 transcodierten Dateien, die im Laufe des Versuchs erzeugt wurden, enthalten sein. Eigene Experimente mit kreativen Transcodiereinstellungen sind gern gesehen und k\u00f6nnen ebenfalls abgegeben werden.</p> <pre><code>\ud83d\udcc1 Versuch 1\n    \ud83d\udcc4 Clip1_1080p.mp4\n    \ud83d\udcc4 Clip1_720p.mp4\n    \ud83d\udcc4 Clip1_480p.mp4\n    \ud83d\udcc1 Experimente\n        \ud83d\udcc4 Clip2_experiment.mp4\n        ...\n</code></pre>"},{"location":"versuch1/06-troubleshooting/","title":"Troubleshooting","text":""},{"location":"versuch1/06-troubleshooting/#elemental-mediaconvert-darf-nicht-auf-den-s3-bucket-zugreifen-access-denied","title":"Elemental MediaConvert darf nicht auf den S3 Bucket zugreifen (Access denied)","text":"<p>Wenn Elemental MediaConvert nicht die erforderlichen Rechte besitzt, um auf den S3 Objektspeicher zuzugreifen, wird der Transcodierauftrag mit einer Fehlermeldung beendet.</p> <p>Hier lohnt es sich zu kontrollieren, dass beim Transcodierauftrag \"Verwenden einer vorhandenen Servicerolle\" im Bereich \"AWS-Integration\" gew\u00e4hlt wurde und die bereits bestehende Rolle \"MediaConvert_Default_Role\" ausgew\u00e4hlt wurde.</p>"},{"location":"versuch2/01-einfuehrung/","title":"Einf\u00fchrung","text":"<p>In Versuch 2 wird vor allem auf das CDN eingegangen. Die Verteilung der transcodierten Mediendateien steht im Vordergrund. Auf die tiefer gehende Theorie von CDNs wird nicht mehr eingegangen. </p>"},{"location":"versuch2/01-einfuehrung/#grundbegriffe","title":"Grundbegriffe","text":"<p>Als CDN-Anbieter wird Akamai genutzt. Akamai ist einer der global gr\u00f6\u00dften Anbieter f\u00fcr Content Delivery Networks und war 2015 f\u00fcr 15 - 30% des weltweiten Datenverkehrs im Internet verantwortlich<sup>1</sup>.</p> <p>Ebenso wie AWS l\u00e4sst sich Akamai \u00fcber eine Weboberfl\u00e4che oder die API bedienen. In diesem Versuch wird die Weboberfl\u00e4che genutzt.</p> <p>Kosten</p> <p>Wie auch bei AWS werden die Kosten anhand des Aufwandes berechnet. Beim CDN entstehen die meisten Kosten durch die Datenmenge, die summiert an Nutzer \u00fcbertragen wurde. F\u00fcr den Versuch wurde uns ein begrenztes freies Kontingent zur Verf\u00fcgung gestellt.</p>"},{"location":"versuch2/01-einfuehrung/#akamai-adaptive-media-delivery-amd","title":"Akamai Adaptive Media Delivery (AMD)","text":"<p>Zur Verteilung von streambaren Mediendateien hat Akamai das Produkt \"Adaptive Media Delivery\" im Portfolio. Dabei wird das CDN auf die Anforderungen, die beim Streamen von Audio und Video entstehen, konfiguriert und es k\u00f6nnen spezifisch auf Mediendateien zugeschnittene Einstellungen angepasst werden.</p>"},{"location":"versuch2/01-einfuehrung/#akamai-netstorage","title":"Akamai NetStorage","text":"<p>Die im CDN zu verteilenden Daten m\u00fcssen von einem sogenannten Origin-Server eingelesen werden. Dies kann ein externer Speicheranbieter wie AWS sein oder es wird der Akamai-Interne Dienst NetStorage genutzt. Auf NetStorage k\u00f6nnen beispielsweise via ftp, ssh oder rsync Daten hochgeladen werden und so dem CDN zur Verf\u00fcgung gestellt werden.</p>"},{"location":"versuch2/01-einfuehrung/#property","title":"Property","text":"<p>Als Property bezeichnet Akamai eine Konfigurationsdatei, die steuert, wie das CDN auf Anfragen reagieren soll. Pro Property k\u00f6nnen ein oder mehrere Hostnamen hinterlegt werden.</p>"},{"location":"versuch2/01-einfuehrung/#hostnamen","title":"Hostnamen","text":"<p>Damit ein Mediaplayer auf die im CDN gespeicherten Medien zugreifen kann, m\u00fcssen URLs bzw. Hostnamen, wie z.B. <code>cdn.netflix.com</code> bereitgestellt werden. Akamai unterscheidet hier zwischen dem Property Hostname und dem Edge Hostname. </p>"},{"location":"versuch2/01-einfuehrung/#property-hostname","title":"Property Hostname","text":"<p>Im Normalfall ist der Property Hostname die Adresse der eigenen Domain, unter dem die Medien verf\u00fcgbar sein sollen. Im Falle des ZDFs k\u00f6nnte dies <code>cdn.zdf.de</code> sein. F\u00fcr diesen Versuch steht keine eigene Domain zu Verf\u00fcgung, weswegen wir als Property Hostname auch eine Domain von Akamai nutzen.</p>"},{"location":"versuch2/01-einfuehrung/#edge-hostname","title":"Edge Hostname","text":"<p>Der Edge Hostname ist das \u00c4quivalent zum Property Hostname aufseiten von Akamai. Dieser k\u00f6nnte z.B. lauten <code>zdf.akamaized.net</code>. In der Praxis verweist der DNS-Eintrag des Property Hostname auf den Edge Hostname und die Daten k\u00f6nnen abgerufen werden.</p> <p> </p>"},{"location":"versuch2/01-einfuehrung/#akamai-webgui","title":"Akamai WebGUI","text":""},{"location":"versuch2/01-einfuehrung/#login","title":"Login","text":"<p>Die Akamai WebGUI l\u00e4sst sich \u00fcber den Browser auf control.akamai.com aufrufen. Vor Beginn des Versuchs sollte eine Informationsmail mit den Schritten zu einem Passwort angekommen sein. \u00dcber die Funktion \"Passwort vergessen\" l\u00e4sst sich ein eigenes Passwort vergeben.</p> <p></p> <p>Sicherheit</p> <p>Akamai verlangt die Nutzung von Multi-Faktor-Authentifizierung. Bitet w\u00e4hlen Sie eines der angebotenen 2FA-Verfahren.</p> <p></p> <p>Nach dem Login landet man auf dem Akamai Control Center Dashboard.</p> <ol> <li> <p>https://de.wikipedia.org/wiki/Akamai\u00a0\u21a9</p> </li> </ol>"},{"location":"versuch2/02-property/","title":"Property","text":"<p>Jeder Student erstellt eine eigene Property, also die Konfigdatei, in der beschrieben wird, wie das CDN auf Anfragen reagieren soll. Dazu wird in der Seitenleiste <code>CDN -&gt; Properties</code> gew\u00e4hlt.</p> <p></p> <p>Auf dem Dashboard werden alle vorhandenen Properties angezeigt.</p> <p></p>"},{"location":"versuch2/02-property/#name","title":"Name","text":"<p>Zum Erstellen einer neuen Property, muss rechts auf \"New Property\" geklickt werden. Zuerst muss das gew\u00fcnschte CDN-Produkt gew\u00e4hlt werden. Da Medien verteilt werden sollen, muss hier \"Adaptive Media Delivery\" gew\u00e4hlt werden. Dies sollte die einzige Option sein.</p> <p>Danach kann der Name der Property festgelegt werden. Hier soll der HDS-Anmeldenamen (z.B. <code>faschmab</code>) gew\u00e4hlt werden.</p> <p></p>"},{"location":"versuch2/02-property/#konfiguration","title":"Konfiguration","text":"<p>Ist der Name best\u00e4tigt, werden die tiefer gehende Konfiguration festgelegt. Zuerst m\u00fcssen Hostnamen hinzugef\u00fcgt werden.</p>"},{"location":"versuch2/02-property/#hostnamen","title":"Hostnamen","text":"<p>Im Bereich \"Property Hostnames\" muss auf den Button \"+ Hostnames\" geklickt werden und die Option \"Add Instant Config Hostname\" gew\u00e4hlt werden.</p> <p>Info</p> <p>\u00dcblicherweise steht f\u00fcr die Konfiguration eine eigene Domain bzw. Subdomain wie <code>cdn.eigene-website.de</code> zur Verf\u00fcgung. In diesem Fall m\u00fcsste der Punkt \"Add Hostname(s)\" gew\u00e4hlt werden. Im Zuge dessen kann ein Akamai-Interner Hostname gew\u00e4hlt werden und der eigene Hostname eingegeben werden.</p> <p>Da f\u00fcr diesen Versuch keine eigene Domain zur Verf\u00fcgung steht, wird mit der Option \"Add Instant Config Hostname\" ein Akamai Hostname f\u00fcr beide Hostnames genutzt.</p> <p></p> <p>Im erschienenen Fenster soll nun der Edge Hostname auf den HDS-Anmeldenamen (z.B. <code>faschmab</code>) gesetzt werden. Der Hostname hat damit die Struktur <code>[username].mdc.akamaized.net</code>. Die IP-Version muss nicht ver\u00e4ndert werden. Als Segmented Media Mode soll \"VOD\" gew\u00e4hlt werden.</p> <p></p> <p>Mit dem Klick auf \"Confirm\" wird der Hostname angelegt.</p> <p></p>"},{"location":"versuch2/02-property/#settings","title":"Settings","text":"<p>Die Property Configuration Settings legen fest, wie das CDN auf Anfragen reagiert. Wie eine Firewall werden die erstellten Regeln nacheinander abgearbeitet. Trifft eine Regel zu, wird mit der Anfrage wie in dieser Regel definiert verfahren und der Prozess ist abgeschlossen. </p> <p>Im Falle von Akamai durchl\u00e4uft eine Anfrage die Regeln von unten nach oben. Sollen verschieden Medien oder Live und VOD \u00fcber die gleiche Property verteilt werden, kann dies mit mehreren Regeln gel\u00f6st werden. F\u00fcr diesen Versuch ben\u00f6tigen wir lediglich die automatisch erstellte \"Default Rule\". Diese wird in den folgenden Schritten modifiziert.</p>"},{"location":"versuch2/02-property/#origin-server","title":"Origin Server","text":"<p>Als Erstes muss der Origin Server festgelegt werden. Hier soll der schon bestehende NetStorage Account \"MVS\" ausgew\u00e4hlt werden. (Der Name \"MVS\" kann in Ihrem Semester etwas anders lauten, z.B. MVS2)</p> <p></p>"},{"location":"versuch2/02-property/#content-provider-code","title":"Content Provider Code","text":"<p>Der Content Provider Code erleichtert das Abrechnen der Kosten, wenn viele verschiedene CDNs und Produkte genutzt werden. F\u00fcr diesen Versuch wurde bereits ein CP-Code erstellt (<code>1652421 - mvs-aws-versuch</code>). Dieser kann aus der Liste gew\u00e4hlt werden.</p> <p></p>"},{"location":"versuch2/02-property/#origin-location","title":"Origin Location","text":"<p>Da der NetStorage Origin Server in Europa konfiguriert wurde, muss im Bereich \"Origin Characteristics\" die Einstellung \"Origin Location\" auf \"Europe\" gesetzt werden.</p> <p></p>"},{"location":"versuch2/02-property/#content-characteristics","title":"Content Characteristics","text":"<p>Im Bereich Content Characteristics kann das CDN individuell auf die verwendeten Medien eingestellt werden. Da in diesem Versuch sowohl die Anzahl der Clips sehr gering ist (im Vergleich zu kommerziellen Anbietern) soll die Katalog-Gr\u00f6\u00dfe auf \"Small\" gestellt werden. Der Content Type kann bei \"High Definition\" belassen werden. Die Protokolle HDS, DASH und Smooth sollen deaktiviert werden, da die verwendeten Clips in HLS vorliegen.</p> <p></p> <p>Frage 1</p> <p>Recherchieren Sie, welche Firmen oder Standardisierungsgremien hinter den verschiedenen Streaming-Protokollen stehen. Welche Protokolle sind heute noch relevant? Nennen Sie beispielhaft einen Streaming-Anbieter und welches Protokoll dieser nutzt. (Quelle angeben)</p>"},{"location":"versuch2/02-property/#origin-base-path","title":"Origin Base Path","text":"<p>Zuletzt soll noch eine neue Eigenschaft zu der Regel hinzugef\u00fcgt werden. Ganz unten \u00fcber den Button \"+ Behavior\" kann dies getan werden.</p> <p>Hier soll die Eigenschaft \"Origin Base Path\" hinzugef\u00fcgt werden.</p> <p></p> <p>Ist die neue Eigenschaft hinzugef\u00fcgt, soll im Feld \"Base Path\" der HDS-Nutzername umrahmt von zwei Schr\u00e4gstrichen eingetragen. </p> <p></p> <p>Frage 2</p> <p>Welchen Effekt hat diese zus\u00e4tzliche Eigenschaft?</p>"},{"location":"versuch2/02-property/#speichern","title":"Speichern","text":"<p>Um die Einstellungen der Property zu speichern, wird der Button \"Save\" genutzt. Im Gegensatz zu AWS MediaConvert wird die erstellte Konfiguration nicht direkt ausgef\u00fchrt, sondern muss erst aktiviert werden.</p> <p>Info</p> <p>Soll zu einem sp\u00e4teren Zeitpunkt eine aktivierte Property-Einstellung ver\u00e4ndert werden, muss jedoch eine neue Version dieser Property-Einstellung erstellt werden. Daf\u00fcr wird der Button \"Edit New Version\" genutzt und die Versionsnummer der Einstellung wird erh\u00f6ht. Die ge\u00e4nderte Konfiguration muss danach erst aktiviert werden, um einen Effekt zu haben.</p>"},{"location":"versuch2/02-property/#aktivierung","title":"Aktivierung","text":"<p>Damit die erstellte Konfiguration an das CDN weitergegeben wird, muss diese aktiviert werden. Dazu w\u00e4hlt man den Reiter \"Activate\" aus.</p> <p></p> <p>Es kann zwischen der Aktivierung im \"Staging Network\" und im \"Production Network\" gew\u00e4hlt werden. Das \"Staging Network\" ist ein eigenes CDN mit angepassten Hostnamen, um \u00c4nderungen erst einmal testen zu k\u00f6nnen, bevor die \u00c4nderungen auf alle Nutzer angewendet werden. So k\u00f6nnen Fehler in der Konfiguration behoben werden, bevor es zu Ausf\u00e4llen bei Nutzern kommt. Das \"Production Network\" ist das regul\u00e4re CDN \u00fcber welches Nutzer die Medienstreams abrufen.</p> <p>Im Normalfall sollte die Konfiguration erst im Staging Network getestet werden. Da dies jedoch weitergehende Konfiguration zum Testen erfordert, soll ausnahmsweise die Konfiguration direkt im Produktionsnetz aktiviert werden. </p> <p>Dazu klickt man auf \"Activate v1 on Production\" und aktiviert den Haken, der vor der Aktivierung im Produktionsnetz vor dem Staging-Netz warnt.</p> <p></p> <p>Ist die Aktivierung im Gange, wird eine Fortschrittsanzeige im Reiter \"Activate\" angezeigt.</p> <p></p> <p>Der Vorgang der Aktivierung im Produktionsnetz dauert ca. 10 Minuten.</p> <p>Frage 3</p> <p>Warum dauert die Propertyaktivierung eine so lange Zeit?</p> <p>W\u00e4hrend die Aktivierung im Hintergrund durchgef\u00fchrt wird, kann die Konfiguration der Testwerkzeuge vorgenommen werden.</p>"},{"location":"versuch2/03-netstorage/","title":"NetStorage","text":"<p>Wie in den Property-Einstellungen schon festgelegt, sollen die Quelldaten von einem NetStorage Origin Server abgerufen werden. F\u00fcr jeden Teilnehmenden an der AWS-\u00dcbung steht ein eigene Ordner zur Verf\u00fcgung.  F\u00fcr Versuch 2 wurde bereits ein HLS-Clip  auf NetStorage hochgeladen.  Eigene Daten k\u00f6nnen nach Belieben hinzugef\u00fcgt werden. (Hinweis: In Versuch 3 Werden Sie dann \u00fcber AWS MediaConvert erzeugte Streaming-Inhalte automatisiert auf NetStorage kopieren).</p>"},{"location":"versuch2/03-netstorage/#zugriff","title":"Zugriff","text":"<p>Auf NetStorage kann auf verschiedenen Wegen zugegriffen werden. Darunter sind unter Andrem <code>rsync</code>, <code>ssh</code> oder <code>HTTP</code>. F\u00fcr diesen Versuch wird jedoch <code>ftp</code> genutzt.</p> <p>Zur NetStorage \u00dcbersicht gelangt man \u00fcber die Seitenleiste unter <code>Origin Services -&gt; NetStorage</code>.</p> <p></p> <p>Auf der Startseite werden die verf\u00fcgbaren \"Storage Groups\" angezeigt. Diese sind in ihrer Funktion mit Buckets bei AWS zu vergleichen. In der Spalte \"Access Methods\" werden die verf\u00fcgbaren Zugriffsmethoden f\u00fcr die Storage Groups angezeigt.</p> <p></p> <p>Durch einen Klick auf das Personen-Symbol in der linken Leiste werden die verf\u00fcgbaren Upload Accounts angezeigt. F\u00fcr jeden Teilnehmer des Praktikums ist ein eigener Nutzer erstellt.</p> <p></p>"},{"location":"versuch2/03-netstorage/#filezilla","title":"FileZilla","text":"<p>Um auf den Origin Server via ftp zuzugreifen, wird ein FTP-Client ben\u00f6tigt. Daf\u00fcr empfiehlt sich FileZilla. Dieser kann hier heruntergeladen werden. Sollte keine dauerhafte Installation gew\u00fcnscht sein, kann die Windows-Datei ohne \"setup\" im Namen heruntergeladen und entpackt werden.</p> <p></p> <p>In der oberen Leiste kann der Server sowie Nutzername und Passwort eingetragen werden. Der Nutzername ist der eigene HDS-Nutzername und das Passwort setzt sich wie beim AWS-Login auch aus Nutzername, Matrikelnummer und Ausrufezeichen (z.B. <code>musterst12345!</code>) zusammen.</p> <p>Der linke Bereich ist das lokale Dateisystem. Hier k\u00f6nnen die Dateien, die hochgeladen werden sollen, ausgew\u00e4hlt werden und per Drag-and-Drop auf die andere Seite verschobene werden.</p> <p>Im rechten Bereich befindet sich das Dateisystem auf der Serverseite.</p> <p>Der Fortschritt der \u00dcbertragung wird im unteren Bereich angezeigt.</p> <p>Frage 4</p> <p>Dokumentieren Sie, welche Manifest-Dateien (*.m3u8) f\u00fcr den gesamten Clip sowie die einzelnen Qualit\u00e4tsstufen bereits in Ihrem Ordner vorhanden sind.</p>"},{"location":"versuch2/04-inhalte_abrufen/","title":"Inhalte Abrufen","text":"<p>Die Inhalte sind nun \u00fcber das CDN erreichbar. Der HLS-Stream kann damit \u00f6ffentlich abgerufen werden. Um die Funktion des CDNs zu testen, soll im ersten Schritt kontrolliert werden, dass der HLS-Stream ordnungsgem\u00e4\u00df abgerufen und in verschiedenen Qualit\u00e4tsstufen wiedergegeben werden kann. Im zweiten Schritt soll kontrolliert werden, dass je nach geografischer Lage ein passender Edge Server im CDN gew\u00e4hlt wird und der DNS Eintrag auf diesen verweist.</p>"},{"location":"versuch2/04-inhalte_abrufen/#hls-player","title":"HLS-Player","text":"<p>Zum Testen der HLS-Funktionalit\u00e4t soll die Demo-Instanz von hls.js genutzt werden. hls.js ist eine quelloffene JavaScript Bibliothek, die HLS-Streams im Browser wiedergeben kann. Der Demoplayer ist unter https://hlsjs.video-dev.org/demo/ zu finden.</p> <p>Kompatibilit\u00e4t</p> <p>Auf meinem Mac konnte die Seite via Safari zwar geladen werden, das Video konnte aber nicht gestartet werden. Auf anderen HLS-Playern trat das gleiche Problem auf. \u00dcber den Firefox Browser funktionierte es jedoch problemlos.</p> <p>Sollten auch bei Ihnen Probleme auftreten l\u00f6st ein andere Browser unter Umst\u00e4nden das Problem.</p> <p></p> <p>Standardm\u00e4\u00dfig ist in der Wiedergabe-URL ein Testvideo eingetragen. Hier soll die Akamai-URL der <code>.m3u8</code>-Datei ohne ein Qualit\u00e4tssufix wie <code>_720p</code> eingetragen werden. Die URL besteht aus der Basis-URL (<code>http://username.mdc.akamaized.net/</code>) und dem Pfad zur entsprechenden HLS-Playlist-Datei (z.B. <code>ftp_source/playlist.m3u8</code>).</p> <p>Kompatibilit\u00e4t</p> <p>Denken Sie daran, den Ordner, in der sich die Playlist-Datei befindet, auch mit anzugeben.</p>"},{"location":"versuch2/04-inhalte_abrufen/#http-und-https","title":"HTTP und HTTPS","text":"<p>Da wir keine eigene Domain f\u00fcr das CDN nutzen, wird auch ein Akamai-Eigenes HTTPS Zertifikat genutzt. Dieses wird von Firefox als \"Nicht sicher\" markiert und verhindert das Laden im HLS-Player. Daher muss die URL mit einem http angegeben werden. Sie sollte circa dieser Form entsprechen:</p> <pre><code>http://musterstudent.mdc.akamaized.net/bbb/CPL_xxxxx.m3u8\n</code></pre> <p>Das Laden von HTTP Inhalten auf einer HTTPS Website ist standardm\u00e4\u00dfig deaktiviert. Dies l\u00e4sst sich jedoch tempor\u00e4r \u00fcberbr\u00fccken. Am einfachsten ist dies mithilfe von Firefox m\u00f6glich: https://support.mozilla.org/en-US/kb/mixed-content-blocking-firefox</p> <p>Dazu ruft man den HLS-Player auf, gibt den Link zur Playlist ein und dr\u00fcckt enter. Danach klickt man auf das Schloss in der URL-Leiste in Firefox. Danach klickt man auf \"Verbindung ist sicher\" und klickt auf \"Schutz momentan deaktiveren\". Bei neueren (05/25) Firefox-Versionen scheint das nciht mehr zu funktionieren. Weitere M\u00f6glichkeit: In der Firefox-Adresszeile <code>about:config</code>eingeben. Dann die Option <code>security.mixed_content.block_active_content</code> auf <code>false</code> setzen und die HLS-Player-Seite neu laden.</p> <p></p>"},{"location":"versuch2/04-inhalte_abrufen/#abspielen","title":"Abspielen","text":"<p>Mithilfe der Schaltfl\u00e4chen unter dem Abspielfenster k\u00f6nnen die Qualit\u00e4tsstufen des Streams gew\u00e4hlt werden und Echtzeit-Statistiken des Video-Streams angezeigt werden</p> <p></p> <p>Frage 5</p> <p>Welche Qualit\u00e4tsstufen sind im HLS-Stream enthalten? Geben Sie jeweils die vertikale Aufl\u00f6sung an.</p>"},{"location":"versuch2/04-inhalte_abrufen/#dns","title":"DNS","text":""},{"location":"versuch2/04-inhalte_abrufen/#nslookup","title":"nslookup","text":"<p>Zuerst soll die Namensaufl\u00f6sung innerhalb der Hochschule getestet werden. Daf\u00fcr muss die Kommandozeile ge\u00f6ffnet werden und der Befehl <code>nslookup</code> ausgef\u00fchrt werden. Als Argument des Befehls muss der Akamai Hostname angeh\u00e4ngt werden, damit der Befehl folgender Struktur folgt:</p> <pre><code>nslookup musterstudent.mdc.akamaized.net\n</code></pre> <p></p> <p>Im oberen Bereich wird der verwendete DNS-Server angezeigt. Dies ist in meinem Fall ein lokaler DNS-Server. Darunter werden die IP-Adressen zu dem aufgel\u00f6sten Hostnamen angezeigt.</p> <p>Frage 6</p> <p>F\u00fchren Sie den Befehl in der Hochschule aus. F\u00fcgen Sie einen Screenshot der Ausgabe in ihrem Versuchsbericht ein. Recherchieren Sie mithilfe einer GeoIP Webseite (z.B. https://www.maxmind.com/en/geoip-demo) den ungef\u00e4hren Standort und Betreiber der gelisteten IP-Adressen.</p> <p>Falls Sie diesen Teil des Versuchs nicht in der Hochschule durchf\u00fchren, notieren Sie im Bericht die Stadt, in der nslookup ausgef\u00fchrt wurde.</p>"},{"location":"versuch2/04-inhalte_abrufen/#online-dns-auflosung","title":"Online DNS Aufl\u00f6sung","text":"<p>Um zu sehen, ob die Namensaufl\u00f6sung einen nahen EdgeServer w\u00e4hlt, m\u00fcsste normalerweise der geografische Standort ver\u00e4ndert werden. Dies w\u00e4re beispielsweise mithilfe eines VPN-Anbieters m\u00f6glich. F\u00fcr diesen Versuch reicht jedoch eine Online DNS Namensaufl\u00f6sung.</p> <p>Dazu soll die Webseite https://www.nslookup.io/ verwendet werden. Hier kann der bei nslookup verwendete Hostname eingetragen werden und auf \"Find DNS records\" geklickt werden.</p> <p></p> <p>Ausgegeben werden die verschiedenen DNS-Eintr\u00e4ge, die f\u00fcr diesen Hostnamen gefunden wurden. Hierbei wird standardm\u00e4\u00dfig der Cloudflare-DNS-Service verwendet.</p> <p></p> <p>Der Bereich \"A records\" zeigt die IPv4 Adressen des Hostnamen an und der Bereich \"AAAA records\" die IPv6 Eintr\u00e4ge.</p> <p>Frage 7</p> <p>F\u00fchren Sie eine GeoIP Abfrage durch. In welchem Land befinden sich die angezeigten IPs?</p> <p>Frage 8</p> <p>Welche Bedeutung haben die CNAME-Werte neben den IPv4 und IPv6 Adressen? Beschreiben Sie, was CNAME ist und welche Rolle es in CDNs spielt.</p>"},{"location":"versuch2/04-inhalte_abrufen/#lokale-dns","title":"Lokale DNS","text":"<p>Klicken Sie nun auf den Reiter \"Local DNS\" und w\u00e4hlen Sie S\u00fcdafrika aus. Nun wird eine DNS-Abfrage aus S\u00fcdafrika durchgef\u00fchrt.</p> <p></p> <p>Frage 9</p> <p>F\u00fchren Sie eine GeoIP Abfrage durch. In welchem Land befinden sich die angezeigten IP? Was bedeutet dies f\u00fcr den Abruf des HLS-Streams aus S\u00fcdafrika?</p>"},{"location":"versuch2/05-fazit/","title":"Fazit","text":"<p>In Versuch 2 wurden die Grundprinzipien eines Akamai CDNs zur Medienverteilung erl\u00e4utert und eine eigene Property im CDN erstellt. Die zur Verf\u00fcgung gestellten HLS-Dateien wurden zum CDN hinzugef\u00fcgt und konnten im Anschluss \u00fcber das CDN abgerufen werden.</p>"},{"location":"versuch2/05-fazit/#abgabe","title":"Abgabe","text":"<p>In der Abgabe m\u00fcssen bei Versuch 2 keine eigenen Dateien abgegeben werden. Die Bewertung erfolgt allein anhand des Versuchsberichtes und der darin enthaltenen Screenshots.</p>"},{"location":"versuch3/01-einfuehrung/","title":"Einf\u00fchrung","text":"<p>In diesem letzten Versuch sollen Transcoding und CDN automatisiert werden. Sobald eine Quelldatei hinzugef\u00fcgt wird, soll diese in die passenden Formate transcodiert werden und zum Akamai CDN hinzugef\u00fcgt werden. W\u00e4hrenddessen sollen Statusmeldungen per E-Mail verschickt werden.</p> <p>Der gesamte Worflow ist in folgendem Flowchart dargestellt:</p> <p> </p> <p>Wird eine Datei in den Ordner <code>ingest</code> hochgeladen, wird die erste Lambda-Funktion ausgel\u00f6st. Diese erstellt einen Transcoding-Auftrag und \u00fcbergibt diesen an MediaConvert. Ist der Auftrag abgeschickt, soll au\u00dferdem die Statusmeldung \"Auftrag erstellt\" per Mail versendet werden.</p> <p>Wird eine fertig transcodierte Datei zum <code>Export</code>-Ordner hinzugef\u00fcgt, soll eine zweite Lambda-Funktion ausgel\u00f6st werden. Diese l\u00e4d die generierten Dateien via ftp zum Akamai Origin Server hoch.</p>"},{"location":"versuch3/01-einfuehrung/#grundbegriffe","title":"Grundbegriffe","text":""},{"location":"versuch3/01-einfuehrung/#aws-lambda","title":"AWS Lambda","text":"<p> AWS Lambda ist eine Plattform, auf der anhand eines Ausl\u00f6sers Funktionen in verschiedenen Programmiersprachen ausgef\u00fchrt werden k\u00f6nnen. Daf\u00fcr ist kein Servermanagement n\u00f6tig und nur die Zeit der Berechnung wird in Rechnung gestellt.</p> <p>Die in Lambda erstellten Funktionen k\u00f6nnen anhand eines Ausl\u00f6sers ausgef\u00fchrt werden und mit den richtigen Berechtigungen auf andere AWS Ressourcen zugreifen. In diesem Versuch bildet Lambda das R\u00fcckgrat der Automatisierung des Prozesses. Wird eine neue Datei im S3 Speicher abgelegt, wird dadurch eine Lambda-Funktion ausgel\u00f6st, die einen Transcoding-Auftrag erstellt und startet.</p> <p>Kosten</p> <p>Wie bei vielen anderen Services steigen die Kosten, je mehr die Services genutzt werden. Da Funktionen in Lambda im Normalfall keine gro\u00dfen Berechnungen ausf\u00fchren, werden erst ab mehrerer Millionen Ausf\u00fchrungen pro Monat Kosten signifikant. Achtet man jedoch nicht darauf, wie oft ein Ausl\u00f6ser eine Funktion anst\u00f6\u00dft, k\u00f6nnen die Kosten im industriellen Umfeld schnell steigen.</p>"},{"location":"versuch3/01-einfuehrung/#aws-sns","title":"AWS SNS","text":"<p> \u00dcber den AWS Simple Notification Service, kurz SNS, k\u00f6nnen Nachrichten von Applikation zu Applikation oder von Applikation zu Nutzer verteilt werden. SNS funktioniert \u00fcber ein Pub/Sub-System, bei dem Nachrichten von einem Ersteller in einem Themen-Kanal ver\u00f6ffentlicht werden k\u00f6nnen (Publish) und Empf\u00e4nger die Nachrichten empfangen, solange sie den entsprechenden Themen-Kanal abonniert haben (Subscribe).</p> <p>Die Zustellung von einem Service zu Nutzern geschieht wahlweise \u00fcber SMS- oder Push-Nachrichten, sowie via E-Mail. SNS ist nicht f\u00fcr z.B. Newsletter gedacht, sondern f\u00fcr interne Kommunikation.</p> <p>Kosten</p> <p>Wie auch bei Labda fallen erst Kosten ab 1 Millionen Anfragen an. Diese k\u00f6nnen in einem industriellen Umfeld anfallen, werden aber in diesem Versuch nicht ansatzweise erreicht.</p>"},{"location":"versuch3/02-s3_vorbereitungen/","title":"S3 Vorbereitungen","text":"<p>F\u00fcr diesen Versuch werden Unterordner im bereits vorhandenen S3 Bucket ben\u00f6tigt. Diese sollen die Namen <code>ingest</code>, <code>export</code> und <code>templates</code> tragen. In <code>ingest</code> sollen die zu transcodierenden Dateien abgelegt werden. <code>export</code> soll der Ausgabeordner f\u00fcr MediaConvert sein, von dem aus die Dateien via ftp zu Akamai hochgeladen werden. <code>templates</code> soll die Codierungseinstellungen enthalten.</p>"},{"location":"versuch3/02-s3_vorbereitungen/#unterordner-erstellen","title":"Unterordner erstellen","text":"<p>Um den Unterordner zu erstellen, muss auf der AWS Weboberfl\u00e4che der entsprechende Bucket ge\u00f6ffnet werden und \u00fcber den Button \"Ordner erstellen\" erstellt werden.</p> <p></p> <p>Au\u00dfer dem Ordnername m\u00fcssen keine weiteren Einstellungen bei der Erstellung festgelegt werden.</p> <p></p> <p>Wiederholen Sie den Vorgang, bis alle drei Ordner erstellt sind.</p> <p></p>"},{"location":"versuch3/02-s3_vorbereitungen/#transcodiervorlage-hinzufugen","title":"Transcodiervorlage hinzuf\u00fcgen","text":"<p>F\u00fcr die automatische Transcodierung muss MediaConvert mitgeteilt werden, welche Transcodierparameter gew\u00e4hlt werden sollen. Dies geschieht \u00fcber Vorlage im JSON-Format. Ein Beispiel f\u00fcr diese Vorlage steht in <code>a--sourcefiles</code> zur Verf\u00fcgung und soll in den Ordner <code>templates</code> kopiert werden.</p> <p>Frage 1</p> <p>Laden Sie die JSON Vorlage herunter und \u00f6ffnen Sie diese in einem Texteditor. Welche Aufl\u00f6sungen werden durch diese Vorlage erzeugt? Welche durchschnittlichen und maximalen Video-Bitraten besitzen die Aufl\u00f6sungen jeweils?</p> <p></p> <p></p> <p>Kontrollieren Sie, dass die Datei in das richtige Verzeichnis kopiert wurde.</p>"},{"location":"versuch3/03-sns/","title":"SNS","text":"<p>Damit die Statusmeldungen per Mail versendet werden k\u00f6nnen, muss ein Ver\u00f6ffentlichungsthema erstellt werden. Diesem Thema kann danach ein Abbonement hinzugef\u00fcgt werden, um die Nachrichten per Mail empfangen zu k\u00f6nnen.</p>"},{"location":"versuch3/03-sns/#thema-erstellen","title":"Thema erstellen","text":"<p>\u00dcber die Suchleiste kann die Startseite von SNS ge\u00f6ffnet werden. Hier l\u00e4sst sich im linken Men\u00fc der Punkt \"Themen\" ausw\u00e4hlen. Hier werden alle erstellten Themen angezeigt. Um ein neues Thema zu erstellen, kann rechts oben \"Thema erstellen\" gew\u00e4hlt werden.</p> <p></p> <p>Als Thementyp muss \"Standard\" ausgew\u00e4hlt werden. Als Name soll der HDS-Nutzername gew\u00e4hlt werden.</p> <p></p> <p></p> <p>Ist das Thema erstellt, kann unten auf \"Abonnement erstellen\" ein Benachrichtigungskanal hinzugef\u00fcgt werden. Hier muss als Protokoll \"Email\" sowie als Endpunkt die eigene Email Adresse gew\u00e4hlt werden.</p> <p></p> <p>Ist das Abonnement erstellt, wird eine Best\u00e4tigungsmail an die angegebene Adresse versendet. \u00dcber den Best\u00e4tigungslink muss das Abonnement best\u00e4tigt werden.</p> <p></p>"},{"location":"versuch3/04-lambda/","title":"Lambda","text":""},{"location":"versuch3/04-lambda/#funktion-1-createjob","title":"Funktion 1: CreateJob","text":"<p>Die erste Funktion soll, wenn neue Dateien dem <code>ingest</code>-Ordner hinzugef\u00fcgt werden, einen entsprechenden Transcodierauftrag erstellen und im Anschluss eine Statusmeldung via SNS versenden.</p> <p>Dazu soll \u00fcber das linke Men\u00fc der Punkt \"Funktionen\" angeklickt und auf der \u00dcbersicht der Funktionen auf \"Funktion erstellen\" klicken. Der Funktionsname soll folgenderma\u00dfen aufgebaut sein: <code>[HDS-Nutzername]-CreateJob</code>. Als Laufzeit soll Python gew\u00e4hlt werden. Im Unterpunkt \"Standard-Ausf\u00fchrungsrolle \u00e4ndern\" soll die Option \"Verwenden einer vorhandenen Rolle\" gew\u00e4hlt werden und die bestehende Rolle \"MVS_Lambda_Role\" gew\u00e4hlt werden.</p> <p></p> <p>Sind die Infos eingetragen, kann auf \"Funktion erstellen\" geklickt werden, um die Funktion zu erstellen.</p> <p></p>"},{"location":"versuch3/04-lambda/#ausloser-hinzufugen","title":"Ausl\u00f6ser hinzuf\u00fcgen","text":"<p>Damit die Funktion beim Hinzuf\u00fcgen einer neuen Datei aufgerufen wird, muss ein Ausl\u00f6ser hinzugef\u00fcgt werden. Dies kann \u00fcber die Schaltfl\u00e4che \"Ausl\u00f6ser hinzuf\u00fcgen\" oder im Reiter \"Konfiguration -&gt; Ausl\u00f6ser\" geschehen.</p> <p></p> <p>Als Quelle soll S3 gew\u00e4hlt werden. Im Feld \"Bucket\" soll der eigene Bucket ausgew\u00e4hlt werden. Im Feld \"Prefix\" soll der Ingest-Ordner angegeben werden (also <code>ingest/</code>) und im Suffix \"mp4\". So wird die Funktion nur f\u00fcr hinzugef\u00fcgte MP4-Dateien im Ordner \"Ingest\" aufgerufen. </p> <p>Kosten</p> <p>Zum Schluss muss noch Akzeptiert werden, dass wenn Funktionen das gleiche Output-Verzeichnis wie Input-Verzeichnis aufweisen, es schnell zu hohen Kosten durch rekursive Aufrufe kommen kann. Pr\u00fcfen Sie daher immer, ob seperate Ein- und Ausgangsverzeichnisse angegeben sind.</p> <p></p> <p>Ist der Ausl\u00f6ser erstellt, wird er oben in der \u00dcbersicht angezeigt.</p> <p></p> <p>Info</p> <p>Da es sich bei IMF-Paketen um ganze Ordner handelt, sind diese auch komplexer zu automatisieren. Um die grundlegenden Konzepte besser zu \u00fcbermitteln, werden in diesem Versuch nur mp4-Dateien verwendet. Das gleiche l\u00e4sst sich aber auch auf IMF-Pakete \u00fcbertragen.</p>"},{"location":"versuch3/04-lambda/#code","title":"Code","text":"<p>Frage 2</p> <p>Versehen Sie den Code mit Kommentaren, die die einzelnen Abschnitte und Befehle beschreiben. Es muss nicht zu jedem Befehl ein Kommentar geschrieben werden, dokumentieren Sie den Code aber so, dass die Funktionsweise ersichtlich wird. </p> <p>F\u00fcgen Sie den kommentierten Code entweder als .py-Datei der Abgabe hinzu oder integrieren Sie den Code als Bild oder Text in den Bericht.</p> <p>Im Nachfolgenden soll der Python-Code in die automatisch erstellte Datei \"lambda_function.py\" kopiert werden.</p> <pre><code>import boto3\nimport json\n\ndef lambda_handler(event, context):\n\n    s3 = boto3.client('s3')\n    sns = boto3.client('sns')\n\n    topic_arn = 'arn:aws:sns:xxxxxxxxx'\n    queue= 'arn:aws:mediaconvert:eu-central-1:757773874047:queues/Default'\n\n    bucket = event['Records'][0]['s3']['bucket']['name']\n    media_key = event['Records'][0]['s3']['object']['key']\n    media_path = \"s3://\" + bucket + \"/\" + media_key\n    substring1 = media_key.rsplit('/', 1)\n    substring2 = substring1[1].rsplit('.', 1)\n    export_path = \"s3://\" + bucket + \"/export/\" + substring2[0] + \"/\"\n    username = bucket.replace(\"mvs-\", \"\") + \" - \"\n\n    try:\n        file = s3.get_object(Bucket=bucket, Key=\"templates/hls_template.json\")\n    except:\n        status = \"An exception occured while downloading the transcoding template\"\n        sns.publish(TopicArn=topic_arn, Message=status)\n    template_json = json.loads(file['Body'].read())\n\n    template_json['Settings']['Inputs'][0]['FileInput'] = media_path\n    template_json['Settings']['OutputGroups'][0]['OutputGroupSettings']['HlsGroupSettings']['Destination'] = export_path\n\n    for key in range(len(template_json['Settings']['OutputGroups'][0]['Outputs'])) : \n        template_json['Settings']['OutputGroups'][0]['Outputs'][key]['VideoDescription']['VideoPreprocessors'] = {}\n        template_json['Settings']['OutputGroups'][0]['Outputs'][key]['VideoDescription']['VideoPreprocessors']['TimecodeBurnin'] = {}\n        template_json['Settings']['OutputGroups'][0]['Outputs'][key]['VideoDescription']['VideoPreprocessors']['TimecodeBurnin']['FontSize'] = 16\n        template_json['Settings']['OutputGroups'][0]['Outputs'][key]['VideoDescription']['VideoPreprocessors']['TimecodeBurnin']['Prefix'] = username\n    template_json.update(template_json)\n\n    mediaconvert = boto3.client('mediaconvert', region_name='eu-central-1', endpoint_url='https://yk2lhke4b.mediaconvert.eu-central-1.amazonaws.com')\n\n    try:\n        response = mediaconvert.create_job(\n            Role=\"arn:aws:iam::757773874047:role/MediaConvert_Default_Role\",\n            Settings=template_json['Settings'],\n            Queue=queue\n        )\n        status = \"Transcoding Job created successfully. Job-ID: \" + response['Job']['Id']\n        sns.publish(TopicArn=topic_arn, Message=status)\n    except:\n        status = \"An exception occured while creating the transcoding job\"\n        sns.publish(TopicArn=topic_arn, Message=status)\n\n    print(\"Job-ID: \" + response['Job']['Id'])\n</code></pre> <p>Damit die Transcoding-Auftr\u00e4ge in der richtigen Warteschlange landen und die Ergebnisse in das richtige SNS Thema ver\u00f6ffentlicht werden, m\u00fcssen die folgenden Punkte im Code modifiziert werden:</p> <p>In Zeile 9 muss die topic_arn durch das eigene Thema aus SNS ersetzt werden. Die topic_arn findet man in der Themen\u00fcbersicht in der Liste in der Spalte \"ARN\". </p> <p>In Zeile 10 muss au\u00dferdem die Warteschlange eingetragen werden. Dabei kann einfach \"Default\" durch die entsprechende Warteschlange ersetzt werden. Es soll die gleiche Warteschlange wie in Versuch 1 genutzt werden, die auch in der Mail mit den Zugangsdaten zu finden ist.</p> <p>Ist der Code hinzugef\u00fcgt und modifiziert, kann die Lambdafunktion mithilfe des Buttons \"Deploy\" aktualisiert werden.</p> <p></p>"},{"location":"versuch3/04-lambda/#weitere-einstellungen","title":"Weitere Einstellungen","text":"<p>Damit die Funktion reibungslos ablaufen kann, muss noch eine weitere Option ge\u00e4ndert werden. Da die Erstellung des Auftrages und das Abrufen der Transcodiereinstellungen verh\u00e4ltnism\u00e4\u00dfig lang dauert, muss das Timeout der Funktion vergr\u00f6\u00dfert werden. Das Timeout dient dazu, dass Funktionen sich nicht in Endlosschleifen verfangen und damit viel Geld kosten.</p> <p>Im Reiter <code>Konfiguration -&gt; Allgemeine Konfiguration</code> kann das Timeout ge\u00e4ndert werden. Dazu klickt man auf \"Bearbeiten\" und w\u00e4hlt ein Timeout von 10 Sekunden. Dies sollte ausreichend sein, um die Funktion auszuf\u00fchren (Die durchschnittliche Ausf\u00fchrungszeit liegt bei ca. 2,5 Sekunden).</p> <p></p>"},{"location":"versuch3/04-lambda/#funktion-2-uploadfiles","title":"Funktion 2: UploadFiles","text":"<p>Die zweite Funktion soll bei neuen Dateien im Ordner <code>export/</code> die entsprechenden Dateien via FTP zu Akamai hochladen.</p> <p>Die Lambda Funktion soll wie bei der ersten Funktion erstellt werden. Der Name soll sich diesmal wie folgt zusammengesetzt werden: <code>[HDS-Nutzername]-UploadFile</code>. Als Laufzeit soll wieder Python gew\u00e4hlt werden. Ebenso soll die Standard-Ausf\u00fchrungsrolle wie bei Funktion 1 ge\u00e4ndert werden.</p>"},{"location":"versuch3/04-lambda/#ausloser","title":"Ausl\u00f6ser","text":"<p>Als Ausl\u00f6ser soll diesmal \"export/\" eingetragen werden. Die Suffix-Filterung kann leer gelassen werden.</p> <p></p>"},{"location":"versuch3/04-lambda/#code_1","title":"Code","text":"<p>Frage 3</p> <p>Versehen Sie den Code mit Kommentaren, die die einzelnen Abschnitte und Befehle beschreiben. Es muss nicht zu jedem Befehl ein Kommentar geschrieben werden, dokumentieren Sie den Code aber so, dass die Funktionsweise ersichtlich wird. </p> <p>F\u00fcgen Sie den kommentierten Code entweder als .py-Datei der Abgabe hinzu oder integrieren Sie den Code als Bild oder Text in den Bericht.</p> <p>Im Nachfolgenden soll der Python-Code in die automatisch erstellte Datei \"lambda_function.py\" kopiert werden.</p> <pre><code>import json\nimport os\nimport json\nfrom ftplib import FTP\nimport boto3\n\nFTP_HOST = 'mvs.ftp.upload.akamai.com'\nFTP_USER = 'musterstudent'\nFTP_PWD = 'xxxxxxxxxxxx'\n\nftp = FTP(FTP_HOST, FTP_USER, FTP_PWD)\n\ns3_client = boto3.client('s3')\n\ndef lambda_handler(event, context):\n\n    if event and event['Records']:\n        for record in event['Records']:\n            sourcebucket = record['s3']['bucket']['name']\n            sourcekey = record['s3']['object']['key']\n\n            ftp_path = sourcekey.replace(\"export/\", \"\")\n            ftp_folder = ftp_path.rsplit('/', 1)\n\n            print(ftp_path)\n\n            filename = os.path.basename(sourcekey)\n            download_path = '/tmp/'+ filename\n            print(download_path)\n            s3_client.download_file(sourcebucket, sourcekey, download_path)\n\n            os.chdir(\"/tmp/\")\n            with FTP(FTP_HOST, FTP_USER, FTP_PWD) as ftp, open(filename, 'rb') as file:\n                if directory_exists(ftp_folder[0]) is False: \n                    ftp.mkd(ftp_folder[0])\n                ftp.cwd(ftp_folder[0])\n                ftp.storbinary(f'STOR {filename}', file)\n\n\n            os.remove(filename)\n\n# Check if directory exists (in current location)\ndef directory_exists(dir):\n    filelist = []\n    ftp.retrlines('LIST',filelist.append)\n    for f in filelist:\n        if f.split()[-1] == dir and f.upper().startswith('D'):\n            return True\n    return False\n</code></pre> <p>In Zeile 7 bis 9 m\u00fcssen die Login-Daten f\u00fcr den Akamai ftp Origin Server eingetragen werden.</p>"},{"location":"versuch3/04-lambda/#weitere-einstellungen_1","title":"Weitere Einstellungen","text":"<p>Sollen gro\u00dfe Dateien hochgeladen werden, ist es unter Umst\u00e4nden n\u00f6tig, das Timeout zu vergr\u00f6\u00dfern. Au\u00dferdem muss bei gro\u00dfen Dateien die Gr\u00f6\u00dfe des fl\u00fcchtigen Speichers erh\u00f6ht werden. Bei den kleinen Transport-Stream Dateien ist dies jedoch nicht n\u00f6tig.</p>"},{"location":"versuch3/05-testen/","title":"Testen","text":""},{"location":"versuch3/05-testen/#test-mit-der-erzeugten-transcodiervorlage","title":"Test mit der erzeugten Transcodiervorlage","text":"<p>Um die automatische Transcodierung zu testen, soll eine mp4-Datei aus dem S3-Bucket \"a--sourcefiles\" mithilfe der S3 Weboberfl\u00e4che in den Ingestordner kopiert werden. Danach sollte automatisch ein neuer Transcodierauftrag bei MediaConvert gestartet werden.</p> <p>Nach der Transcodierung kann auf dem FTP-Server nachgesehen werden, ob die Inhalte automatisch hochgeladen wurden. Das Abspielen kann wie in Versuch 2 mithilfe des HLS-Players geschehen.</p>"},{"location":"versuch3/05-testen/#status-der-bearbeitung-uberprufen","title":"Status der Bearbeitung \u00fcberpr\u00fcfen","text":"<p>Der Status der Ausf\u00fchrung der Lambda-Funktionen kann \u00fcber den AWS-Service CloudWatch verfolgt werden. Dort sind auch m\u00f6gliche Fehlermeldungen sichtbar. \u00dcber die Suchleiste den Service Cloudwatch ausw\u00e4hlen. Unter \"Protokolle\" \"Protokollgruppen\" aufrufen. In der \u00dcbersicht sehen Sie Ihre Lambda-Funktionen. Durch Klick auf die jeweilige Funktion k\u00f6nnen Sie den Status der letzten Aufrufe abrufen.</p>"},{"location":"versuch3/05-testen/#eigene-transcodier-vorlage","title":"Eigene Transcodier-Vorlage","text":"<p>Eigene Transcodiervorlagen k\u00f6nnen in der Mediaconvert GUI erstellt werden. Dazu muss in Mediaconvert der Punkt \"Aufgabenvorlagen\" gew\u00e4hlt werden. Hier kann unter \"Vorlage erstellen\" eine eigene Vorlage erstellt werden.</p> <p></p> <p>Zuerst muss der Name der Vorlage gew\u00e4hlt werden. Hierbei soll wieder der eigene HDS-Nutzername als Pr\u00e4fix verwendet werden, sodass der Name der Vorlage folgendem Schema folgt: <code>musterstudent_template2</code>. Die Felder \"Kategorie\" und \"Beschreibung\" k\u00f6nnen leer gelassen werden.</p> <p></p> <p>Nun k\u00f6nnen unter \"Eingaben\" und \"Ausgabegruppen\" wie gewohnt die Transcodierungseinstellungen festgelegt werden.</p> <p>Frage 4</p> <p>W\u00e4hlen Sie eigene Transcodierungs-Einstellungen. Probieren Sie andere Codecs, Bitraten, Seitenverh\u00e4ltnisse oder Farbkorrekturen aus. Dabei sollen die gew\u00e4hlten Parameter beispielsweise auf bestimmte Ger\u00e4te wie das eigene Handy zugeschnitten sein oder anderweitig von den bisherigen Transcodierungseinstellungen abweichen. Dokumentieren Sie im Bericht Ihre Wahl.</p> <p>Info</p> <p>Das CDN wurde auf die Wiedergabe von HLS-Streams konfiguriert, daher sollte auch HLS als Ausgabeformat gew\u00e4hlt werden.</p> <p></p> <p>Sind alle Parameter festgelegt, kann die Vorlage mithilfe des Buttons \"erstellen\" erstellt werden. Danach kann \u00fcber den Button \"JSON exportieren\" die entsprechen JSON-Datei erstellt und heruntergeladen werden.</p> <p></p> <p>Damit die neu erstellte Vorlage vom Workflow verwendet werden kann, muss die JSON-Datei im eigenen S3-Bucket in den Ordner \"templates\" hochgeladen werden. In der Lambda-Funktion, die f\u00fcr das Erstellen des Transcodierauftrages zust\u00e4ndig ist, muss nun nur noch der Pfad der Vorlagendatei auf die neue Datei angepasst werden.</p> <p>Neu ingestierte Mediendateien sollten dann mithilfe der neuen Vorlage transcodiert werden.</p>"},{"location":"versuch3/06-fazit/","title":"Fazit","text":"<p>In Versuch 3 wurden die Grundprinzipien eines automatisieren Transcoding-Workflows erl\u00e4utert und ein solcher in AWS erstellt. Sobald Rohmaterial ingestiert wurde, wurde dieses in HLS transcodiert und zum Origin-Server des CDNs hochgeladen.</p>"},{"location":"versuch3/06-fazit/#abgabe","title":"Abgabe","text":"<p>In der Abgabe sollte mindestens ein Beispiel f\u00fcr transcodierte Dateien mit der gegebenen Vorlage und ein Beispiel f\u00fcr transcodierte Dateien mit der eigenen Vorlage enthalten sein. Dabei m\u00fcssen nicht alle Dateien in die Abgabe eingef\u00fcgt werden, sondern jeweils nur die Index-Dateien und ein Segment jeder Qualit\u00e4tsstufe.</p> <p>Au\u00dferdem k\u00f6nnen die Lambdafunktionen CreateJob und UploadFile als .py-Datei abgegeben werden, falls sie nicht als Screenshot oder Text im Bericht enthalten sind.</p> <pre><code>\ud83d\udcc1 Versuch 3\n    \ud83d\udcc1 Standard Vorlage\n        \ud83d\udcc4 Clip1.m38u\n        \ud83d\udcc4 Clip1_480p.m38u\n        \ud83d\udcc4 Clip1_720p.m38u\n        \ud83d\udcc4 Clip1_1080p.m38u\n        \ud83d\udcc4 Clip1_480p_00001.ts\n        \ud83d\udcc4 Clip1_720p_00001.ts\n        \ud83d\udcc4 Clip1_1080p_00001.ts\n    \ud83d\udcc1 Eigene Vorlage\n        \ud83d\udcc4 Clip2.m38u\n        \ud83d\udcc4 Clip2_low.m38u\n        \ud83d\udcc4 Clip2_high.m38u\n        \ud83d\udcc4 Clip2_low_00001.ts\n        \ud83d\udcc4 Clip2_high_00001.ts\n    \ud83d\udcc1 Templates\n        \ud83d\udcc4 musterstudent_template2.json\n        ...\n    ...\n</code></pre>"},{"location":"versuch3/07-troubleshooting/","title":"Troubleshooting","text":""},{"location":"versuch3/07-troubleshooting/#ingestierte-datei-wird-nicht-transcodiert","title":"Ingestierte Datei wird nicht transcodiert","text":"<p>Werden ingestierte Dateien nicht automatisch transcodiert, liegt der Fehler meist in der Lambda-Funktion. Um dies zu kontrollieren, sollte erst in MediaConvert nachgeschaut werden, ob der Transcodierauftrag \u00fcberhaupt erstellt wurde. Wurde der Auftrag gar nicht erstellt, liegt das Problem bei Lambda. Wurde der Auftrag erstellt, aber wurde aufgrund eines Fehlers abgebrochen, kann die Fehlermeldung in MediaConvert nachgelesen werden.</p>"},{"location":"versuch3/07-troubleshooting/#lambda-funktion-erstellt-keinen-transcodierauftrag","title":"Lambda-Funktion erstellt keinen Transcodierauftrag","text":"<p>Wird kein Transcodierauftrag erstellt, liegt dies an der Lambda-Funktion. Als Erstes sollte kontrolliert werden, dass die Queue usw. richtig eingetragen wurden. Zus\u00e4tzlich sollte \u00fcberpr\u00fcft werden, ob die Funktion korrekt aus der Versuchsanleitung kopiert wurde. Werden keine Probleme erkannt, kann AWS CloudWatch ge\u00f6ffnet werden. Dort finden sich unter \"Protokollgruppen\" die Log-Daten der Lambda-Funktionen. Fehler beim Ausf\u00fchren der Funktionen werden hier angezeigt.</p>"},{"location":"versuch3/07-troubleshooting/#transcodierte-datei-wird-nicht-hochgeladen","title":"Transcodierte Datei wird nicht hochgeladen","text":"<p>Wird eine ingestierte Datei zwar transcodiert, aber nicht via FTP hochgeladen, liegt der Fehler vermutlich in der Lambda-Upload-Funktion. Hier sollten vor allem die FTP-Zugangsdaten kontrolliert werden. Ebenso sollte \u00fcberpr\u00fcft werden, ob der Funktions-Code korrekt aus der Versuchsanleitung \u00fcbernommen wurde. L\u00e4sst sich der Fehler so nicht beheben, kann ebenfalls via AWS CloudWatch in die Logs Einsicht genommen werden.</p>"},{"location":"versuch4/01-einfuehrung/","title":"Einf\u00fchrung","text":"<p>In diesem Versuch soll n\u00e4her auf die Kommandozeile und die APIs von AWS eingegangen werden. Zuerst werden einige Befehle auf der AWS CloudShell ausgef\u00fchrt und danach werden die Lambda-Funktionen aus Versuch 3 mit zus\u00e4tzlichen Funktionen ausgestattet.</p>"},{"location":"versuch4/01-einfuehrung/#grundbegriffe","title":"Grundbegriffe","text":""},{"location":"versuch4/01-einfuehrung/#aws-cloudshell","title":"AWS CloudShell","text":"<p> AWS CloudShell bietet Zugang zu einer voreingestellte Kommandozeile \u00fcber den Browser. Die n\u00f6tigen APIs und Bibliotheken sowie gebr\u00e4uchliche Entwicklertools (z.B. Python) sind bereits installiert. Somit ist beispielsweise die Installation der AWS-Kommandozeile auf dem lokalen PC nicht n\u00f6tig.</p> <p>In der CloudShell gespeicherte Scripte und sonstige Daten werden auch nach dem Schlie\u00dfen des Browsers gespeichert. Bis zu 1GB Daten lassen sich im Benutzerverzeichnis ablegen.</p> <p>Bei CloudShell handelt es sich um ein Entwicklungstool. Sollen z.B. Python-Scripts anhand von Ausl\u00f6sern oder regelm\u00e4\u00dfig ausgef\u00fchrt werden, sollte weiterhin Lambda genutzt werden, da sich die CloudShell nach einem Timeout in den Standby-Modus versetzt.</p> <p>Kosten</p> <p>AWS CloudShell wird kostenlos zur Verf\u00fcgung gestellt. Einzig die \u00fcber die CloudShell erstellten Ressourcen kosten wie gewohnt Geld. Datentransfer von der CloudShell zu anderen Services wird zu den \u00fcblichen AWS Konditionen berechnet. Bei den \u00fcblichen geringen Datenmengen sind diese Kosten zu vernachl\u00e4ssigen.</p>"},{"location":"versuch4/01-einfuehrung/#aws-cli","title":"AWS CLI","text":"<p> Der Kommandozeilen-Zugang (engl. Command Line Interface) bietet die M\u00f6glichkeit AWS Ressourcen und Konfigurationen mithilfe der Kommandozeile zu steuern. Das Kommandozeilen-Tool kann sowohl auf dem eignen Rechner installiert als auch \u00fcber AWS CloudShell genutzt werden. Bei der Ausf\u00fchrung in der CloudShell m\u00fcssen keine Authentifizierungs-Daten angegeben werden, da die CloudShell an sich durch den eigenen Benutzer authentifiziert ist.</p> <p>Das Kommandozeilen-Tool kann wie jedes andere Programm der Kommandozeile auch durch ein Bash-Script ausgef\u00fchrt werden. Dies bietet erfahrenen Nutzern der Kommandozeile die M\u00f6glichkeit, schnell eine Reihe von Ressourcen zu erstellen, mehrere Buckets auf einmal zu l\u00f6schen oder ganze Buckets herunterzuladen. </p>"},{"location":"versuch4/01-einfuehrung/#aws-python-sdk-boto3","title":"AWS Python SDK (boto3)","text":"<p> Das Software-Entwicklungs-Kit (SDK) f\u00fcr AWS in Python hei\u00dft boto3. \u00dcber diese Bibliothek k\u00f6nnen, wie auch mit der Kommandozeile Ressourcen aufgelistet, erstellt und gel\u00f6scht werden.</p> <p>Das Ausf\u00fchren von Python-Scripten mit der boto3 Bibliothek ist ohne weitere Einstellungen von der AWS CloudShell m\u00f6glich. Neben der automatischen Authentifizierung bietet die Ausf\u00fchrung in der CloudShell eine deutlich geringere Latenz als die Ausf\u00fchrung auf dem lokalen PC.</p>"},{"location":"versuch4/02-cloudshell/","title":"AWS CloudShell","text":"<p>Die AWS CloudShell kann auf der Web-Konsole durch die Suchfunktion gefunden werden oder direkt mit dem Kommandozeilen-Symbol oben rechts gestartet werden.</p> <p></p>"},{"location":"versuch4/02-cloudshell/#kommando-aufbau","title":"Kommando-Aufbau<sup>1</sup>","text":"<p>Das AWS Kommandozeilen-Tool ist nach den einzelnen Produkten gegliedert. Der erste Befehl an die Kommandozeile gibt dabei das Produkt / den Service an. Nachfolgende Befehle werden auf diesem Service ausgef\u00fchrt. Anschaulicher l\u00e4sst sich dies mit Beispielen erkl\u00e4ren:</p> <pre><code>aws s3 ls\n</code></pre> <p></p> <p>Dabei ruft <code>aws</code> die AWS CLI auf, <code>s3</code> legt den Service, in diesem Fall AWS S3, fest und <code>ls</code> ist der auszuf\u00fchrende Befehl. Wie auch in Linux-Systemen steht <code>ls</code> f\u00fcr \"list\" und listet alle enthaltenen Elemente, in diesem Fall S3-Buckets auf.</p> <p>Frage 1</p> <p>F\u00fchren Sie den oben angegebenen Befehl aus. Welche Buckets werden angezeigt. Dokumentieren Sie die Ausgabe mit einem Screenshot.</p>"},{"location":"versuch4/02-cloudshell/#parameter","title":"Parameter","text":"<p>Um die Parameter eines Befehls anzupassen, wird wie bei anderen Kommandozeilenprogrammen verfahren. Soll eine Datei vom S3-Bucket auf die Cloudshell kopiert werden, kann dieser Befehl ausgef\u00fchrt werden:</p> <pre><code>aws s3 cp s3://a--sourcefiles/hls_template.json . --dryrun\n</code></pre> <p>Bei diesem Befehl wird <code>cp</code>, also eine Kopieroperation, ausgef\u00fchrt. Der S3-Pfad danach gibt die Quelldatei an. Danach wird mit \".\" der Zielpfad angegeben. Der Punkt bedeutet dabei, dass der Zielpfad der Ort ist, von dem der Befehl ausgef\u00fchrt wird. Die Option <code>--dryrun</code> f\u00fchrt den Befehl nur \"auf dem Trockenen\", also ohne das wirkliche Kopieren der Datei aus. Auf der Kommandozeile werden trotzdem alle Statusmeldungen wie \u00fcblich ausgegeben.</p> <p>Um zu \u00fcberpr\u00fcfen, ob eine Datei in die CloudShell kopiert wurde, kann der Befehl <code>ls</code> in der CloudShell ausgef\u00fchrt werden (ohne <code>aws s3</code> davor). Dieser Befehl listet die Dateien im aktuellen Pfad der CloudShell auf.</p> <p>Frage 2</p> <p>F\u00fchren Sie den \"cp\"-Befehl mit der Option \"--dryrun\" aus. F\u00fchren Sie danach den Befehl ohne die \"--dryrun\"-Option aus. Dokumentieren Sie die \u00c4nderungen und kontrollieren sie mit <code>ls</code>, ob die Datei in das Dateisystem der CloudShell kopiert wurde.</p> <ol> <li> <p>https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-commandstructure.html \u21a9</p> </li> </ol>"},{"location":"versuch4/03-python_sdk/","title":"Python SDK","text":"<p>Das Ausf\u00fchren einzelner Befehle kann manche Aufgaben im Gegensatz zur Weboberfl\u00e4che vereinfachen. Die M\u00f6glichkeiten der Automation werden jedoch erst durch Scripte ausgereizt. Neben Bash bietet Python einen guten Einstieg in die Scriptsprachen und bietet im Gegensatz zu Bash mehr M\u00f6glichkeiten. </p> <p>Info</p> <p>Damit bei der Erstellung der Nutzer f\u00fcr diese \u00dcbung nicht 20 Nutzernamen h\u00e4ndisch eingetragen werden m\u00fcssen, wurde f\u00fcr diese Aufgabe ein Script erstellt, welches die teilnehmenden Studierenden einliest, Nutzer und Passw\u00f6rter erstellt und die n\u00f6tigen Berechtigungen vergibt. Durch ein Akamai Python-Paket erstellt dieses Script ebenso die Nutzer in Akamai.</p> <p>Im Folgenden sollen die bestehenden Python-Scripts in den Lambda-Funktionen um zus\u00e4tzliche Funktionen durch das AWS Python SDK erweitert werden.</p>"},{"location":"versuch4/03-python_sdk/#automatische-warteschlangen-auswahl","title":"Automatische Warteschlangen-Auswahl","text":"<p>Im ersten Schritt soll die Lambda-Funktion automatisch die optimale Warteschlange ausw\u00e4hlen. Optimal bedeutet in diesem Falle, dass keine feste Warteschlange festgelegt wird, sondern immer die Warteschlange mit den wenigsten wartenden Transcoding-Jobs. Sollten mehrere Warteschlangen mit keinen wartenden Jobs existieren, soll m\u00f6glichst eine Warteschlange ohne laufenden Job gew\u00e4hlt werden.</p> <p>Mithilfe der Funktion <code>list_queues</code> k\u00f6nnen die Eigenschaften der Warteschlangen abgefragt werden. In der Dokumentation ist nachzulesen, dass in der Antwort die Eigenschaften <code>ProgressingJobsCount</code> und <code>SubmittedJobsCount</code> sowie die Eigenschaft <code>Arn</code> \u00fcbermittelt werden. Die ARN ist eine eindeutige Zeichenkette, die als Verweis zur Warteschlange dient und der Funktion <code>create_job</code> \u00fcbergeben wird.</p> <p></p>"},{"location":"versuch4/03-python_sdk/#zusatzlichen-code-einfugen","title":"Zus\u00e4tzlichen Code einf\u00fcgen","text":""},{"location":"versuch4/03-python_sdk/#1-warteschlangen-abrufen","title":"1. Warteschlangen abrufen","text":"<p>Der folgende Code-Ausschnitt speichert die Liste der Warteschlangen in der Variable <code>response</code> und extrahiert daraus die Liste der Warteschlangen:</p> <pre><code>response = mediaconvert.list_queues()\nqueues = response['Queues']\n</code></pre>"},{"location":"versuch4/03-python_sdk/#2-warteschlangen-sortieren","title":"2. Warteschlangen sortieren","text":"<p>Um die Warteschlangen zu sortieren, soll die Funktion <code>sorted</code> verwendet werden. Dieser Funktion k\u00f6nnen folgende Parameter \u00fcbergeben werden:</p> <ul> <li><code>iterable</code> / Eine Liste (oder andere Form von aneinandergereihte Daten), die sortiert werden sollen</li> <li><code>key</code> / Eine individuelle Sortier-Funktion (optional)</li> <li><code>reverse</code> / Wenn auf <code>True</code> gesetzt wird in umgekehrter Reihenfolge (Absteigend) sortiert.</li> </ul> <pre><code>sorted_queues = sorted(queues, key=SORTING_KEY)\n</code></pre> <p>Als Key soll folgende Struktur genutzt werden:</p> <pre><code>lambda q: (q['Key1'], q['key2'])\n</code></pre> <p>Dabei sind <code>Key1</code> und <code>Key2</code> die Eigenschaften der Warteschlange, anhand der sortiert werden soll. Die Liste wird erst anhand von Key1 und danach anhand von Key2 sortiert. W\u00e4hlen Sie als Key1 die Eigenschaft (siehe oben) f\u00fcr die aktuelle Anzahl der Jobs in der Queue und als Key2 die Eigenschaft f\u00fcr die Anzahl der aktuell bearbeiteten Jobs.</p>"},{"location":"versuch4/03-python_sdk/#3-warteschlange-zuweisen","title":"3. Warteschlange zuweisen","text":"<p>Um die Warteschlange dem Transcoding-Job zuzuweisen, kann die Variable <code>queue</code> mit der ARN der am h\u00f6chsten stehenden Warteschlange \u00fcberschrieben werden. Der <code>print</code>-Befehl schreibt die gew\u00e4hlte Queue in den CloudWatch-Log.</p> <pre><code>queue = sorted_queues[0]['Arn']\nprint(f\"Gewaehlte Queue: {queue}\")\n</code></pre> <p>Frage 3</p> <p>Implementieren Sie den zus\u00e4tzlichen Code in Ihre \"CreateJob\" Lambdafunktion aus Versuch 3. Der Code soll nach <code>mediaconvert = boto3.client</code> eingesetzt werden. Ersetzen Sie <code>Key1</code> und <code>Key2</code> durch die Suchkriterien. Die genaue Schreibweise der Eigenschaften einer Warteschlange kann auch im \"Response Syntax\" der Boto3 Dokumentation nachgelesen werden.</p> <p>Dokumentieren und kommentieren Sie den eingesetzten Code im Bericht.</p>"},{"location":"versuch4/03-python_sdk/#funktion-testen","title":"Funktion testen","text":"<p>Durch Hinzuf\u00fcgen einer Datei in den bereits bekannten \"Ingest\"-Ordner wird die Lambdafunktion automatisch ausgef\u00fchrt. Nun soll die Funktion jedoch manuell getestet werden, um Fehler fr\u00fchzeitig zu erkennen. Dies kann \u00fcber den Button \"Test\" geschehen. Wurde noch kein Testereignis erstellt, \u00f6ffnet sich die Eingabemaske, um ein neues Testereignis zu erstellen.</p> <p>Der Ereignis-Name kann frei festgelegt werden. Nun muss noch die Ereignis-JSON ge\u00e4ndert werden. Diese wird der Lambdafunktion auch bei automatischer Ausf\u00fchrung \u00fcbergeben und beschreibt, wodurch die Funktion ausgel\u00f6st wurde. Im Falle einer neuen Datei z.B. den Pfad, die Gr\u00f6\u00dfe und vieles mehr.</p> <p>Damit die Funktion testweise durch eine bestehende Datei ausgel\u00f6st wird, muss die Ereignis-JSON wie folgt aussehen:</p> <pre><code>{\n  \"Records\": [\n    {\n      \"s3\": {\n        \"bucket\": {\n          \"name\": \"mvs-musterstudent\"\n        },\n        \"object\": {\n          \"key\": \"ingest/versuch3_thx.mp4\"\n        }\n      }\n    }\n  ]\n}\n</code></pre> <p>Der Name des Buckets sowie der Key der Datei muss individuell abge\u00e4ndert werden.</p> <p>Warnung</p> <p>Die Datei muss auch wirklich unter dem eingetragenen Pfad zu finden sein. Sehen Sie daher vorher in einem zweiten Tab im S3 Bucket nach, welche Dateien in Ihrem Bucket vorhanden sind.</p> <p></p> <p>Ist das Testereignis erstellt, kann es \u00fcber den Test-Button ausgel\u00f6st werden.</p> <p>Frage 4</p> <p>L\u00f6sen Sie das Testereignis aus und dokumentieren Sie das Ergebnis. Im Bereich \"Function Logs\" wird die Job-ID angezeigt. Im Service MediaConvert finden Sie unter Ihrer Job-ID die verwendete Warteschlange. Dokumentieren Sie bitte die Job-ID und die verwendete Warteschlange.</p>"},{"location":"versuch4/03-python_sdk/#volle-warteschlangen-simulieren","title":"Volle Warteschlangen simulieren","text":"<p>Die Warteschlangen sind unter Umst\u00e4nden zum Zeitpunkt des Tests nicht ausgelastet und es wurde die erste Warteschlange gew\u00e4hlt. Um ausgelastete Warteschlangen zu simulieren, kann die Liste der Warteschlangen manuell \u00fcberschrieben werden. Dazu m\u00fcssen zwischen <code>queues = response['Queues']</code> und <code>sorted_queues = sorted(...)</code> folgende Zeilen eingef\u00fcgt werden:</p> <pre><code>json_string = '[{\"Arn\": \"arn:aws:mediaconvert:eu-central-1:757773874047:queues/Default\", \"Name\": \"Default\", \"PricingPlan\": \"ON_DEMAND\", \"ProgressingJobsCount\": 1, \"Status\": \"ACTIVE\", \"SubmittedJobsCount\": 5, \"Type\": \"SYSTEM\"}, {\"Arn\": \"arn:aws:mediaconvert:eu-central-1:757773874047:queues/Queue_01\", \"Name\": \"Queue_01\", \"PricingPlan\": \"ON_DEMAND\", \"ProgressingJobsCount\": 1, \"Status\": \"ACTIVE\", \"SubmittedJobsCount\": 2, \"Type\": \"CUSTOM\"}, {\"Arn\": \"arn:aws:mediaconvert:eu-central-1:757773874047:queues/Queue_02\", \"Name\": \"Queue_02\", \"PricingPlan\": \"ON_DEMAND\", \"ProgressingJobsCount\": 1, \"Status\": \"ACTIVE\", \"SubmittedJobsCount\": 1, \"Type\": \"CUSTOM\"}, {\"Arn\": \"arn:aws:mediaconvert:eu-central-1:757773874047:queues/Queue_03\", \"Name\": \"Queue_03\", \"PricingPlan\": \"ON_DEMAND\", \"ProgressingJobsCount\": 1, \"Status\": \"ACTIVE\", \"SubmittedJobsCount\": 1, \"Type\": \"CUSTOM\"}, {\"Arn\": \"arn:aws:mediaconvert:eu-central-1:757773874047:queues/Queue_04\", \"Name\": \"Queue_04\", \"PricingPlan\": \"ON_DEMAND\", \"ProgressingJobsCount\": 0, \"Status\": \"ACTIVE\", \"SubmittedJobsCount\": 1, \"Type\": \"CUSTOM\"}, {\"Arn\": \"arn:aws:mediaconvert:eu-central-1:757773874047:queues/Queue_05\", \"Name\": \"Queue_05\", \"PricingPlan\": \"ON_DEMAND\", \"ProgressingJobsCount\": 1, \"Status\": \"ACTIVE\", \"SubmittedJobsCount\": 1, \"Type\": \"CUSTOM\"}, {\"Arn\": \"arn:aws:mediaconvert:eu-central-1:757773874047:queues/Queue_06\", \"Name\": \"Queue_06\", \"PricingPlan\": \"ON_DEMAND\", \"ProgressingJobsCount\": 1, \"Status\": \"ACTIVE\", \"SubmittedJobsCount\": 1, \"Type\": \"CUSTOM\"}, {\"Arn\": \"arn:aws:mediaconvert:eu-central-1:757773874047:queues/Queue_07\", \"Name\": \"Queue_07\", \"PricingPlan\": \"ON_DEMAND\", \"ProgressingJobsCount\": 1, \"Status\": \"ACTIVE\", \"SubmittedJobsCount\": 1, \"Type\": \"CUSTOM\"}, {\"Arn\": \"arn:aws:mediaconvert:eu-central-1:757773874047:queues/Queue_08\", \"Name\": \"Queue_08\", \"PricingPlan\": \"ON_DEMAND\", \"ProgressingJobsCount\": 1, \"Status\": \"ACTIVE\", \"SubmittedJobsCount\": 1, \"Type\": \"CUSTOM\"}, {\"Arn\": \"arn:aws:mediaconvert:eu-central-1:757773874047:queues/Queue_09\", \"Name\": \"Queue_09\", \"PricingPlan\": \"ON_DEMAND\", \"ProgressingJobsCount\": 1, \"Status\": \"ACTIVE\", \"SubmittedJobsCount\": 1, \"Type\": \"CUSTOM\"}]'\nqueues = json.loads(json_string)\n</code></pre> <p>Mit einem Klick auf \"Deploy\" k\u00f6nnen die \u00c4nderungen \u00fcbernommen und der Test wiederholt gestartet werden.</p> <p>Frage 5</p> <p>Dokumentieren Sie die \u00c4nderungen im Code und f\u00fchren Sie den Test ein weiteres Mal aus. Welche Warteschlange wurde nun gew\u00e4hlt?</p>"},{"location":"versuch4/04-fazit/","title":"Fazit","text":"<p>In Versuch 4 wurden die Grundlagen der Steuerung von AWS \u00fcber die CLI und Python demonstriert. Die in Versuch 3 erstellte Funktion \"CreateJob\" wurde im Zuge dessen angepasst, um immer die optimale Warteschlange zu w\u00e4hlen.</p>"},{"location":"versuch4/04-fazit/#abgabe","title":"Abgabe","text":"<p>In der Abgabe f\u00fcr Versuch 4 m\u00fcssen keine eigenen Dateien abgegeben werden. Die Bewertung erfolgt allein anhand der Codebeispiele und Bildschirmfotos im Bericht.</p>"},{"location":"versuch4/05-troubleshooting/","title":"Troubleshooting","text":""},{"location":"versuch4/05-troubleshooting/#cloudwatch-logs","title":"CloudWatch Logs","text":"<p>Wird die Lambda-Funktion nicht ordnungsgem\u00e4\u00df ausgef\u00fchrt, k\u00f6nnen unter Umst\u00e4nden die Log-Dateien Einblick in den Fehler geben. Die Logs lassen sich im Reiter \"\u00dcberwachen -&gt; Protokolle\" in der Lambdafunktion einsehen. Sollen die gesamten Logs angezeigt werden, kann \u00fcber den Button \"CloudWatch-Protokolle anzeigen\" die CloudWatch-Oberfl\u00e4che ge\u00f6ffnet werden.</p>"}]}